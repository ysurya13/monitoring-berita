{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9252cf8",
   "metadata": {},
   "source": [
    "# SETTING ENVIRONMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52389a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# mount the colab with google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# mount the colab with google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771e26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set folder tempat kerja (current working directory)\n",
    "import os\n",
    "cwd = \"/Users/yusufpradana/Library/CloudStorage/OneDrive-Personal/Pekerjaan BMN/05. 2025/98_monitoring_berita/monitoring-berita\"\n",
    "#cwd = '/content/drive/MyDrive/Monitoring Berita'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7aa5d",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da78eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:00,196 - INFO - Membaca file analisis AI: 00_hasil_analisis/seluruh_berita/analisis_ai_20250930_deepseek_default.csv\n",
      "2025-09-30 13:41:00,200 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,200 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:00,200 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,200 - INFO - Berita penting (filtered): 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat 2 berita penting\n",
      "\n",
      "Sample berita penting:\n",
      "                                        judul_berita topik_llm  importance  \\\n",
      "0  Prabowo Sebut Pemerintah Tutup 1.000 Tambang I...  Kemenkeu          85   \n",
      "2  Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp ...  Kemenkeu          65   \n",
      "\n",
      "  sentimen  \n",
      "0  positif  \n",
      "2  negatif  \n"
     ]
    }
   ],
   "source": [
    "# Langkah pertama membaca file csv hasil analisis AI sebelumnya\n",
    "# file terletak di config.json \"analisis_ai_output\"\n",
    "# Filter out berita dengan topik_llm \"Lainnya\"\n",
    "# Filter out berita dengan importance < 50\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging untuk error handling\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_berita_penting():\n",
    "    \"\"\"\n",
    "    Memuat dan memfilter berita penting dari file hasil analisis AI\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame berisi berita yang sudah difilter\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Baca konfigurasi\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Path file analisis AI\n",
    "        analisis_file = config.get('analisis_ai_output')\n",
    "        if not analisis_file:\n",
    "            raise ValueError(\"analisis_ai_output tidak ditemukan dalam config.json\")\n",
    "        \n",
    "        # Periksa apakah file ada\n",
    "        if not Path(analisis_file).exists():\n",
    "            raise FileNotFoundError(f\"File analisis AI tidak ditemukan: {analisis_file}\")\n",
    "        \n",
    "        # Baca file CSV\n",
    "        logger.info(f\"Membaca file analisis AI: {analisis_file}\")\n",
    "        df = pd.read_csv(analisis_file)\n",
    "        \n",
    "        # Filter berita penting\n",
    "        # 1. Exclude topik_llm \"Lainnya\"\n",
    "        # 2. Include importance >= 50\n",
    "        df_filtered = df[\n",
    "            (df['topik_llm'] != 'Lainnya') & \n",
    "            (df['importance'] >= 50)\n",
    "        ].copy()\n",
    "        \n",
    "        logger.info(f\"Total berita: {len(df)}\")\n",
    "        logger.info(f\"Berita penting (filtered): {len(df_filtered)}\")\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            logger.warning(\"Tidak ada berita penting yang memenuhi kriteria!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Urutkan berdasarkan importance (descending)\n",
    "        df_filtered = df_filtered.sort_values('importance', ascending=False)\n",
    "        \n",
    "        return df_filtered\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error dalam load_berita_penting: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load data berita penting\n",
    "df_berita_penting = load_berita_penting()\n",
    "print(f\"Berhasil memuat {len(df_berita_penting)} berita penting\")\n",
    "if not df_berita_penting.empty:\n",
    "    print(\"\\nSample berita penting:\")\n",
    "    print(df_berita_penting[['judul_berita', 'topik_llm', 'importance', 'sentimen']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5631a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fungsi analisis AI telah disiapkan (Updated dengan JSON parsing yang diperbaiki).\n",
      "Untuk melakukan analisis, gunakan: analyze_berita_batch(df_berita_penting, 'openai', 'YOUR_API_KEY')\n",
      "Atau: analyze_berita_batch(df_berita_penting, 'deepseek', 'YOUR_API_KEY')\n"
     ]
    }
   ],
   "source": [
    "# buat format prompt baru untuk menganalisis berita\n",
    "# tanya ke AI untuk mengetahui\n",
    "# 1. Resume \n",
    "# 2. Dampak ke Kementerian Keuangan (positif, negatif, netral)\n",
    "# 3. Alasan dampak\n",
    "# 4. Hal menarik dari berita ini\n",
    "\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def create_analysis_prompt(judul, artikel, source_domain):\n",
    "    \"\"\"\n",
    "    Membuat prompt untuk analisis berita penting\n",
    "    \n",
    "    Args:\n",
    "        judul (str): Judul berita\n",
    "        artikel (str): Isi artikel berita\n",
    "        source_domain (str): Domain sumber berita\n",
    "    \n",
    "    Returns:\n",
    "        str: Prompt untuk AI\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Analisis berita berikut dengan detail:\n",
    "\n",
    "JUDUL: {judul}\n",
    "SUMBER: {source_domain}\n",
    "ARTIKEL: {artikel}\n",
    "\n",
    "Berikan analisis dalam format JSON dengan struktur berikut:\n",
    "{{\n",
    "    \"resume\": \"Ringkasan singkat dan jelas dari berita dalam 2-3 kalimat\",\n",
    "    \"dampak_kemenkeu\": \"positif/negatif/netral\",\n",
    "    \"alasan_dampak\": \"Penjelasan detail mengapa berita ini berdampak positif/negatif/netral terhadap Kementerian Keuangan. Jelaskan kaitan dengan kebijakan fiskal, perpajakan, kepabeanan, keuangan negara, atau fungsi lain Kemenkeu\",\n",
    "    \"hal_menarik\": \"Poin-poin menarik atau insights penting dari berita ini yang perlu mendapat perhatian khusus\"\n",
    "}}\n",
    "\n",
    "Pastikan analisis objektif dan berdasarkan fakta yang ada dalam berita.\n",
    "Berikan response HANYA dalam format JSON, tanpa teks tambahan.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def parse_ai_response(raw_response):\n",
    "    \"\"\"\n",
    "    Parse response dari AI untuk extract JSON\n",
    "    \n",
    "    Args:\n",
    "        raw_response (str): Raw response dari AI\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed JSON atau None jika gagal\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove markdown code blocks jika ada\n",
    "        cleaned_response = raw_response.strip()\n",
    "        \n",
    "        # Remove ```json dan ``` jika ada\n",
    "        if cleaned_response.startswith('```json'):\n",
    "            cleaned_response = cleaned_response[7:]\n",
    "        if cleaned_response.startswith('```'):\n",
    "            cleaned_response = cleaned_response[3:]\n",
    "        if cleaned_response.endswith('```'):\n",
    "            cleaned_response = cleaned_response[:-3]\n",
    "        \n",
    "        cleaned_response = cleaned_response.strip()\n",
    "        \n",
    "        # Try parsing as JSON directly\n",
    "        try:\n",
    "            return json.loads(cleaned_response)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: extract JSON pattern\n",
    "            json_match = re.search(r'\\{.*\\}', cleaned_response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group()\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"No JSON found\", cleaned_response, 0)\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing AI response: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_with_openai(prompt, api_key, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Analisis menggunakan OpenAI API (versi 1.0+)\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Prompt untuk analisis\n",
    "        api_key (str): OpenAI API key\n",
    "        model (str): Model OpenAI yang digunakan\n",
    "    \n",
    "    Returns:\n",
    "        dict: Hasil analisis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize OpenAI client dengan API key\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Anda adalah analis berita ahli yang fokus pada dampak berita terhadap Kementerian Keuangan Indonesia. Selalu berikan response dalam format JSON yang valid.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        raw_content = response.choices[0].message.content\n",
    "        result = parse_ai_response(raw_content)\n",
    "        \n",
    "        if result is None:\n",
    "            logger.error(f\"Failed to parse OpenAI response: {raw_content[:200]}...\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error OpenAI analysis: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_with_deepseek(prompt, api_key, base_url=\"https://api.deepseek.com/v1\"):\n",
    "    \"\"\"\n",
    "    Analisis menggunakan DeepSeek API\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Prompt untuk analisis\n",
    "        api_key (str): DeepSeek API key\n",
    "        base_url (str): Base URL DeepSeek API\n",
    "    \n",
    "    Returns:\n",
    "        dict: Hasil analisis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        data = {\n",
    "            \"model\": \"deepseek-chat\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Anda adalah analis berita ahli yang fokus pada dampak berita terhadap Kementerian Keuangan Indonesia. Selalu berikan response dalam format JSON yang valid.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 1000\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{base_url}/chat/completions\", headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        raw_content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        result = parse_ai_response(raw_content)\n",
    "        \n",
    "        if result is None:\n",
    "            logger.error(f\"Failed to parse DeepSeek response: {raw_content[:200]}...\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error DeepSeek analysis: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_berita_batch(df_berita, ai_provider=\"openai\", api_key=None):\n",
    "    \"\"\"\n",
    "    Analisis batch berita menggunakan AI\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "        ai_provider (str): Provider AI (\"openai\" atau \"deepseek\")\n",
    "        api_key (str): API key untuk AI provider\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame dengan kolom analisis tambahan\n",
    "    \"\"\"\n",
    "    if api_key is None or api_key.strip() == \"\":\n",
    "        logger.warning(\"API key tidak tersedia, skip analisis AI\")\n",
    "        return df_berita\n",
    "    \n",
    "    # Create a copy to avoid modifying original DataFrame\n",
    "    df_result = df_berita.copy()\n",
    "    results = []\n",
    "    \n",
    "    for i, (idx, row) in enumerate(df_berita.iterrows()):\n",
    "        try:\n",
    "            logger.info(f\"Menganalisis berita {i+1}/{len(df_berita)}: {row['judul_berita'][:50]}...\")\n",
    "            \n",
    "            # Buat prompt\n",
    "            prompt = create_analysis_prompt(\n",
    "                row['judul_berita'], \n",
    "                row['artikel_berita_bersih'], \n",
    "                row['source_domain']\n",
    "            )\n",
    "            \n",
    "            # Analisis dengan AI\n",
    "            if ai_provider == \"openai\":\n",
    "                analysis = analyze_with_openai(prompt, api_key)\n",
    "            elif ai_provider == \"deepseek\":\n",
    "                analysis = analyze_with_deepseek(prompt, api_key)\n",
    "            else:\n",
    "                raise ValueError(f\"AI provider tidak dikenali: {ai_provider}\")\n",
    "            \n",
    "            if analysis and isinstance(analysis, dict):\n",
    "                results.append(analysis)\n",
    "                logger.info(f\"âœ… Berhasil menganalisis berita {i+1}\")\n",
    "            else:\n",
    "                # Default jika analisis gagal\n",
    "                results.append({\n",
    "                    \"resume\": \"Analisis tidak tersedia\",\n",
    "                    \"dampak_kemenkeu\": \"netral\",\n",
    "                    \"alasan_dampak\": \"Tidak dapat dianalisis\",\n",
    "                    \"hal_menarik\": \"Tidak dapat dianalisis\"\n",
    "                })\n",
    "                logger.warning(f\"âš ï¸  Analisis gagal untuk berita {i+1}, menggunakan default\")\n",
    "            \n",
    "            # Delay untuk menghindari rate limiting\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing berita {i+1}: {str(e)}\")\n",
    "            results.append({\n",
    "                \"resume\": \"Error dalam analisis\",\n",
    "                \"dampak_kemenkeu\": \"netral\", \n",
    "                \"alasan_dampak\": f\"Error: {str(e)}\",\n",
    "                \"hal_menarik\": \"Tidak dapat dianalisis\"\n",
    "            })\n",
    "    \n",
    "    # Tambahkan hasil analisis ke DataFrame\n",
    "    for i, result in enumerate(results):\n",
    "        original_idx = df_result.index[i]\n",
    "        for key, value in result.items():\n",
    "            df_result.loc[original_idx, f\"ai_{key}\"] = value\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "print(\"âœ… Fungsi analisis AI telah disiapkan (Updated dengan JSON parsing yang diperbaiki).\")\n",
    "print(\"Untuk melakukan analisis, gunakan: analyze_berita_batch(df_berita_penting, 'openai', 'YOUR_API_KEY')\")\n",
    "print(\"Atau: analyze_berita_batch(df_berita_penting, 'deepseek', 'YOUR_API_KEY')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d1609e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREVIEW FORMAT DAFTAR BERITA ===\n",
      "Daftar Berita & Konten\n",
      "Selasa, 30 September 2025\n",
      "Periode pantauan tanggal 29-30 September 2025 (pukul 14.00 s.d. 06.00 WIB)\n",
      "\n",
      "Media Online\n",
      "===========\n",
      "\n",
      "ðŸ”´ [Negatif] Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 Juta Langsung MiskinResearch2 jam yang lalu\n",
      "https://www.cnbcindonesia.com/research/20250929102709-128-670989/rupiah-anjlok-20-vs-real-arab-umroh-bawa-rp-10-juta-langsung-miskin\n",
      "\n",
      "ðŸŸ¢ [Positif] Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilegal di Babel, Selamatkan Rp 22 TriliunNEWS29/09/20...\n"
     ]
    }
   ],
   "source": [
    "# Setelah mendapat informasi terkait berita penting\n",
    "# Format cetakan sehingga sesuai dengan format ini:\n",
    "\n",
    "\"\"\"Daftar Berita & Konten [Judul]\n",
    "Selasa, 30 September 2025 [Tanggal Laporan]\n",
    "Periode pantauan tanggal 29-30 September 2025 (pukul 14.00 s.d. 06.00 WIB) [Waktu Pemantauan]\n",
    "\t\n",
    "Media Online [Judul Bagian]\n",
    "===========\n",
    "\n",
    "\n",
    "ðŸŸ¢ [Sentimen] Purbaya Yakin Kredit Bank Capai 11 Persen Usai Suntikan Dana Rp200 Triliun : Okezone Economy [Judul Berita]\n",
    "https://economy.okezone.com/read/2025/09/29/320/3173364/purbaya-yakin-kredit-bank-capai-11-persen-usai-suntikan-dana-rp200-triliun [url]\n",
    "\n",
    "\n",
    "ðŸŸ¢ [Sentimen] Purbaya Targetkan Ekonomi Indonesia Kuartal IV Tumbuh di Atas 5,5% [Judul Berita]\n",
    "https://ekbis.sindonews.com/read/1626607/33/purbaya-targetkan-ekonomi-indonesia-kuartal-iv-tumbuh-di-atas-55-1759158548 [url]\n",
    "\n",
    "ðŸŸ¢ [Sentimen] Indef Sikap Purbaya Soal Cukai Lindungi Pekerja Industri Rokok [Judul Berita]\n",
    "https://mediaindonesia.com/ekonomi/815843/indef-sikap-purbaya-soal-cukai-lindungi-pekerja-industri-rokok [url]\"\"\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "\n",
    "def get_sentiment_emoji(sentimen):\n",
    "    \"\"\"\n",
    "    Mengkonversi sentimen ke emoji\n",
    "    \n",
    "    Args:\n",
    "        sentimen (str): Sentimen berita (positif, negatif, netral)\n",
    "    \n",
    "    Returns:\n",
    "        str: Emoji yang sesuai\n",
    "    \"\"\"\n",
    "    sentiment_map = {\n",
    "        'positif': 'ðŸŸ¢',\n",
    "        'negatif': 'ðŸ”´', \n",
    "        'netral': 'ðŸŸ¡'\n",
    "    }\n",
    "    return sentiment_map.get(sentimen.lower(), 'ðŸŸ¡')\n",
    "\n",
    "def format_tanggal_indonesia(date_obj):\n",
    "    \"\"\"\n",
    "    Format tanggal dalam bahasa Indonesia\n",
    "    \n",
    "    Args:\n",
    "        date_obj (datetime): Objek datetime\n",
    "    \n",
    "    Returns:\n",
    "        str: Tanggal dalam format Indonesia\n",
    "    \"\"\"\n",
    "    hari_indo = {\n",
    "        'Monday': 'Senin',\n",
    "        'Tuesday': 'Selasa', \n",
    "        'Wednesday': 'Rabu',\n",
    "        'Thursday': 'Kamis',\n",
    "        'Friday': 'Jumat',\n",
    "        'Saturday': 'Sabtu',\n",
    "        'Sunday': 'Minggu'\n",
    "    }\n",
    "    \n",
    "    bulan_indo = {\n",
    "        'January': 'Januari', 'February': 'Februari', 'March': 'Maret',\n",
    "        'April': 'April', 'May': 'Mei', 'June': 'Juni',\n",
    "        'July': 'Juli', 'August': 'Agustus', 'September': 'September',\n",
    "        'October': 'Oktober', 'November': 'November', 'December': 'Desember'\n",
    "    }\n",
    "    \n",
    "    hari_eng = date_obj.strftime('%A')\n",
    "    bulan_eng = date_obj.strftime('%B')\n",
    "    \n",
    "    hari_id = hari_indo.get(hari_eng, hari_eng)\n",
    "    bulan_id = bulan_indo.get(bulan_eng, bulan_eng)\n",
    "    \n",
    "    return f\"{hari_id}, {date_obj.day} {bulan_id} {date_obj.year}\"\n",
    "\n",
    "def generate_daftar_berita_format(df_analyzed, periode_start=None, periode_end=None):\n",
    "    \"\"\"\n",
    "    Generate format daftar berita sesuai template\n",
    "    \n",
    "    Args:\n",
    "        df_analyzed (pd.DataFrame): DataFrame berita yang sudah dianalisis\n",
    "        periode_start (str): Tanggal mulai periode (YYYY-MM-DD)\n",
    "        periode_end (str): Tanggal akhir periode (YYYY-MM-DD)\n",
    "    \n",
    "    Returns:\n",
    "        str: Laporan dalam format yang diinginkan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df_analyzed.empty:\n",
    "            return \"Tidak ada berita penting untuk dilaporkan.\"\n",
    "        \n",
    "        # Tanggal laporan (hari ini)\n",
    "        tanggal_laporan = format_tanggal_indonesia(datetime.now())\n",
    "        \n",
    "        # Periode pemantauan\n",
    "        if periode_start and periode_end:\n",
    "            start_date = datetime.strptime(periode_start, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(periode_end, '%Y-%m-%d')\n",
    "            periode_text = f\"tanggal {start_date.day}-{end_date.day} {format_tanggal_indonesia(end_date).split(', ')[1].split(' ')[1]} {end_date.year}\"\n",
    "        else:\n",
    "            # Default ke kemarin-hari ini\n",
    "            hari_ini = datetime.now()\n",
    "            kemarin = hari_ini - timedelta(days=1)\n",
    "            periode_text = f\"tanggal {kemarin.day}-{hari_ini.day} September 2025\"\n",
    "        \n",
    "        # Header laporan\n",
    "        laporan = f\"\"\"Daftar Berita & Konten\n",
    "{tanggal_laporan}\n",
    "Periode pantauan {periode_text} (pukul 14.00 s.d. 06.00 WIB)\n",
    "\n",
    "Media Online\n",
    "===========\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Group berita berdasarkan sentimen untuk urutan yang baik\n",
    "        df_sorted = df_analyzed.sort_values(['sentimen', 'importance'], ascending=[True, False])\n",
    "        \n",
    "        # Generate entry untuk setiap berita\n",
    "        for idx, row in df_sorted.iterrows():\n",
    "            emoji = get_sentiment_emoji(row['sentimen'])\n",
    "            judul_clean = row['judul_berita'].replace('\\n', ' ').strip()\n",
    "            \n",
    "            # Format entry berita\n",
    "            berita_entry = f\"{emoji} [{row['sentimen'].title()}] {judul_clean}\\n{row['url_berita']}\\n\\n\"\n",
    "            laporan += berita_entry\n",
    "        \n",
    "        return laporan\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating daftar berita format: {str(e)}\")\n",
    "        return f\"Error dalam generate format: {str(e)}\"\n",
    "\n",
    "def save_daftar_berita(laporan_text, output_dir=\"00_laporan_cetak\"):\n",
    "    \"\"\"\n",
    "    Simpan laporan daftar berita ke file\n",
    "    \n",
    "    Args:\n",
    "        laporan_text (str): Teks laporan\n",
    "        output_dir (str): Directory output\n",
    "    \n",
    "    Returns:\n",
    "        str: Path file yang disimpan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Buat directory jika belum ada\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        # Nama file dengan timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"daftar_berita_{timestamp}.txt\"\n",
    "        filepath = Path(output_dir) / filename\n",
    "        \n",
    "        # Simpan file\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(laporan_text)\n",
    "        \n",
    "        logger.info(f\"Laporan daftar berita disimpan: {filepath}\")\n",
    "        return str(filepath)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving daftar berita: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Test format dengan data dummy jika ada data\n",
    "if 'df_berita_penting' in locals() and not df_berita_penting.empty:\n",
    "    print(\"=== PREVIEW FORMAT DAFTAR BERITA ===\")\n",
    "    sample_format = generate_daftar_berita_format(df_berita_penting.head(3))\n",
    "    print(sample_format[:500] + \"...\" if len(sample_format) > 500 else sample_format)\n",
    "else:\n",
    "    print(\"Fungsi format daftar berita telah disiapkan.\")\n",
    "    print(\"Gunakan: generate_daftar_berita_format(df_analyzed) untuk generate laporan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97842265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREVIEW FORMAT NEWS UPDATE ===\n",
      "News Update\n",
      "Lainnya\n",
      "Jakarta, Selasa, 30 September 2025 (Pukul 13.41 WIB)\n",
      "\n",
      "Pemberitaan mengenai lainnya hari ini tercatat terdapat 2 berita (1 positif dan 1 negatif) di media online.\n",
      "\n",
      "Sorotan Media Online\n",
      "â€¢ Presiden Prabowo Subianto\n",
      "â€¢ Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 Juta Langsung Miskin Jakarta, CNBC Indonesia - Tak hanya tertekan terhadap dolar Amerika Serikat (AS)...\n",
      "\n",
      "Tautan Media Online:\n",
      "1. Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilegal di Babel, Selamatkan Rp 22 TriliunNEWS29/09/2025\n",
      "https://nasional.kompas.com/read/2025/09/29/11394051/prabowo-sebut-pemerintah-tutup-1000-tambang-ilegal-di-babel-selamatkan-rp-22\n",
      "2. Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 Juta Langsung MiskinResearch2 jam yang lalu\n",
      "https://www.cnbcindonesia.com/research/20250929102709-128-67...\n"
     ]
    }
   ],
   "source": [
    "# Format kedua terkait dengan news update\n",
    "\n",
    "\"\"\"News Update [Judul] \n",
    "Menkeu Sidak BNI [Topik yang Dipantau diambil dari config.json \"topic_keywords]     \n",
    "Jakarta, 29 September 2025 (Pukul 19.00 WIB) [Periode Pemantauan]\n",
    "\n",
    "Pemberitaan mengenai inspeksi mendadak (sidak) ke kantor pusat PT Bank Negara Indonesia (Persero) Tbk atau BNI hari ini tercatat terdapat 33 berita (30 positif dan 3 netral) di media online. \n",
    "\n",
    "Sorotan Media Online \n",
    "â€¢â   â Menkeu melakukan inspeksi mendadak ke kantor pusat BNI untuk melihat bagaimana kerja BNI pada saat rapat direksi berlangsung.  \n",
    "â€¢â   â Kontroversi kenaikan suku bunga deposito valuta asing (valas) dolar AS menjadi 4% yang dilakukan oleh bank-bank Himbara diduga menjadi latar belakang sidak Menkeu tersebut.  \n",
    "â€¢â   â Sebelumnya Menkeu telah menegaskan bahwa isu kenaikan bunga deposito valas bukan instruksinya dan menolak tuduhan bahwa dirinya mendikte kebijakan perbankan. \n",
    "â€¢â   â Chief Economist Permata Bank, Josua Pardede, menjelaskan risiko yang lebih luas dari kebijakan menaikkan valas dolar AS adalah menguatnya kecenderungan menyimpan kekayaan dalam bentuk dolar. \n",
    "â€¢â   â Menkeu menyebut kedatangannya hanya untuk mengecek langsung penyaluran kredit dari perbankan, khususnya bank-bank yang menerima penempatan dana negara sebesar Rp200 triliun. \n",
    " \n",
    "Tautan Media Online: \n",
    " 1.â  â Purbaya Tiba-tiba Sidak Kantor BNI, Nimbrung Rapat Direksi \n",
    "https://www.cnnindonesia.com/ekonomi/20250929134914-532-1278863/purbaya-tiba-tiba-sidak-kantor-bni-nimbrung-rapat-direksi  \n",
    " 2.â  â Mengapa Menteri Purbaya Inspeksi Mendadak BNI? \n",
    "https://www.tempo.co/ekonomi/mengapa-menteri-purbaya-inspeksi-mendadak-bni--2074388 \n",
    " 3.â  â Mendadak Sidak ke Kantor BNI, Menkeu Purbaya: Boleh Masuk Enggak Ya \n",
    "https://www.beritasatu.com/ekonomi/2926647/mendadak-sidak-ke-kantor-bni-menkeu-purbaya-boleh-masuk-enggak-ya#goog_rewarded \n",
    " 4.â  â Purbaya Sidak Kantor BNI Saat Direksi Lagi Rapat, Ada Apa? \n",
    "https://economy.okezone.com/amp/2025/09/29/320/3173222/purbaya-sidak-kantor-bni-saat-direksi-lagi-rapat-ada-apa \n",
    " 5.â  â Purbaya Sidak Kantor BNI: Saya Mau Lihat Bagaimana Kerja Mereka \n",
    "https://ekbis.sindonews.com/read/1626387/33/purbaya-sidak-kantor-bni-saya-mau-lihat-bagaimana-kerja-mereka-1759129777/5  \n",
    " 6.â  â Menkeu Purbaya Sidak ke Kantor BNI, Ada Apa? \n",
    "https://www.idxchannel.com/amp/economics/menkeu-purbaya-sidak-ke-kantor-bni-ada-apa  \n",
    "\"\"\"\n",
    "\n",
    "def identify_main_topic(df_berita, config_topics):\n",
    "    \"\"\"\n",
    "    Identifikasi topik utama dari berita berdasarkan frequency dan importance\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "        config_topics (list): Daftar topik keywords dari config\n",
    "    \n",
    "    Returns:\n",
    "        str: Topik utama yang teridentifikasi\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df_berita.empty:\n",
    "            return \"Berita Umum\"\n",
    "        \n",
    "        # Analisis topik berdasarkan subtopik_llm dan importance\n",
    "        topic_analysis = df_berita.groupby('subtopik_llm').agg({\n",
    "            'importance': ['mean', 'count'],\n",
    "            'judul_berita': 'first'\n",
    "        }).round(2)\n",
    "        \n",
    "        # Flatten kolom\n",
    "        topic_analysis.columns = ['avg_importance', 'count_berita', 'sample_judul']\n",
    "        \n",
    "        # Hitung skor gabungan (weighted importance)\n",
    "        topic_analysis['weighted_score'] = (\n",
    "            topic_analysis['avg_importance'] * topic_analysis['count_berita']\n",
    "        )\n",
    "        \n",
    "        # Dapatkan topik utama\n",
    "        main_topic = topic_analysis.sort_values('weighted_score', ascending=False).index[0]\n",
    "        \n",
    "        # Cek apakah topik utama ada dalam config topics\n",
    "        for config_topic in config_topics:\n",
    "            if config_topic.lower() in main_topic.lower() or main_topic.lower() in config_topic.lower():\n",
    "                return config_topic.title()\n",
    "        \n",
    "        return main_topic.title()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error identifying main topic: {str(e)}\")\n",
    "        return \"Berita Umum\"\n",
    "\n",
    "def generate_sentiment_summary(df_berita):\n",
    "    \"\"\"\n",
    "    Generate ringkasan sentimen berita\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary sentimen\n",
    "    \"\"\"\n",
    "    sentiment_count = df_berita['sentimen'].value_counts().to_dict()\n",
    "    total = len(df_berita)\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'positif': sentiment_count.get('positif', 0),\n",
    "        'negatif': sentiment_count.get('negatif', 0), \n",
    "        'netral': sentiment_count.get('netral', 0)\n",
    "    }\n",
    "\n",
    "def extract_key_points(df_berita, max_points=5):\n",
    "    \"\"\"\n",
    "    Extract poin-poin kunci dari berita untuk sorotan media online\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "        max_points (int): Maksimal poin yang akan diambil\n",
    "    \n",
    "    Returns:\n",
    "        list: Daftar poin kunci\n",
    "    \"\"\"\n",
    "    try:\n",
    "        points = []\n",
    "        \n",
    "        # Prioritaskan berita dengan importance tinggi\n",
    "        df_sorted = df_berita.sort_values('importance', ascending=False)\n",
    "        \n",
    "        for idx, row in df_sorted.head(max_points).iterrows():\n",
    "            # Gunakan AI analysis jika ada, kalau tidak gunakan poin_of_interest\n",
    "            if 'ai_hal_menarik' in row and pd.notna(row['ai_hal_menarik']):\n",
    "                point = row['ai_hal_menarik']\n",
    "            elif pd.notna(row['poin_of_interest']):\n",
    "                point = row['poin_of_interest']\n",
    "            else:\n",
    "                # Fallback ke statement pejabat atau excerpt dari artikel\n",
    "                if pd.notna(row['statement_pejabat']):\n",
    "                    point = row['statement_pejabat'][:150] + \"...\"\n",
    "                else:\n",
    "                    point = row['artikel_berita_bersih'][:150] + \"...\"\n",
    "            \n",
    "            points.append(point)\n",
    "        \n",
    "        return points\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting key points: {str(e)}\")\n",
    "        return [\"Tidak dapat mengekstrak poin kunci dari berita\"]\n",
    "\n",
    "def generate_news_update_format(df_berita, main_topic=None):\n",
    "    \"\"\"\n",
    "    Generate format News Update sesuai template\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita yang sudah dianalisis\n",
    "        main_topic (str): Topik utama (optional)\n",
    "    \n",
    "    Returns:\n",
    "        str: News Update dalam format yang diinginkan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df_berita.empty:\n",
    "            return \"Tidak ada berita untuk news update.\"\n",
    "        \n",
    "        # Load config untuk topic keywords\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Identifikasi topik utama\n",
    "        if not main_topic:\n",
    "            main_topic = identify_main_topic(df_berita, config.get('topic_keywords', []))\n",
    "        \n",
    "        # Tanggal dan waktu\n",
    "        tanggal_laporan = format_tanggal_indonesia(datetime.now())\n",
    "        waktu_laporan = datetime.now().strftime(\"%H.%M\")\n",
    "        \n",
    "        # Summary sentimen\n",
    "        sentiment_summary = generate_sentiment_summary(df_berita)\n",
    "        \n",
    "        # Generate sentiment text\n",
    "        sentiment_text = []\n",
    "        if sentiment_summary['positif'] > 0:\n",
    "            sentiment_text.append(f\"{sentiment_summary['positif']} positif\")\n",
    "        if sentiment_summary['negatif'] > 0:\n",
    "            sentiment_text.append(f\"{sentiment_summary['negatif']} negatif\")\n",
    "        if sentiment_summary['netral'] > 0:\n",
    "            sentiment_text.append(f\"{sentiment_summary['netral']} netral\")\n",
    "        \n",
    "        sentiment_string = \" dan \".join(sentiment_text) if sentiment_text else \"beragam sentimen\"\n",
    "        \n",
    "        # Extract key points\n",
    "        key_points = extract_key_points(df_berita)\n",
    "        \n",
    "        # Header news update\n",
    "        news_update = f\"\"\"News Update\n",
    "{main_topic}\n",
    "Jakarta, {tanggal_laporan} (Pukul {waktu_laporan} WIB)\n",
    "\n",
    "Pemberitaan mengenai {main_topic.lower()} hari ini tercatat terdapat {sentiment_summary['total']} berita ({sentiment_string}) di media online.\n",
    "\n",
    "Sorotan Media Online\"\"\"\n",
    "        \n",
    "        # Tambahkan key points\n",
    "        for i, point in enumerate(key_points, 1):\n",
    "            news_update += f\"\\nâ€¢ {point}\"\n",
    "        \n",
    "        news_update += \"\\n\\nTautan Media Online:\"\n",
    "        \n",
    "        # Tambahkan daftar berita dengan link\n",
    "        for i, (idx, row) in enumerate(df_berita.head(10).iterrows(), 1):\n",
    "            judul_clean = row['judul_berita'].replace('\\n', ' ').strip()\n",
    "            news_update += f\"\\n{i}. {judul_clean}\\n{row['url_berita']}\"\n",
    "        \n",
    "        return news_update\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating news update format: {str(e)}\")\n",
    "        return f\"Error dalam generate news update: {str(e)}\"\n",
    "\n",
    "def save_news_update(news_update_text, topic=\"general\", output_dir=\"00_laporan_cetak\"):\n",
    "    \"\"\"\n",
    "    Simpan news update ke file\n",
    "    \n",
    "    Args:\n",
    "        news_update_text (str): Teks news update\n",
    "        topic (str): Topik untuk nama file\n",
    "        output_dir (str): Directory output\n",
    "    \n",
    "    Returns:\n",
    "        str: Path file yang disimpan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Buat directory jika belum ada\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        # Nama file dengan timestamp dan topik\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        topic_clean = topic.replace(\" \", \"_\").lower()\n",
    "        filename = f\"news_update_{topic_clean}_{timestamp}.txt\"\n",
    "        filepath = Path(output_dir) / filename\n",
    "        \n",
    "        # Simpan file\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(news_update_text)\n",
    "        \n",
    "        logger.info(f\"News update disimpan: {filepath}\")\n",
    "        return str(filepath)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving news update: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Test format dengan data dummy jika ada data\n",
    "if 'df_berita_penting' in locals() and not df_berita_penting.empty:\n",
    "    print(\"=== PREVIEW FORMAT NEWS UPDATE ===\")\n",
    "    sample_news_update = generate_news_update_format(df_berita_penting.head(5))\n",
    "    print(sample_news_update[:800] + \"...\" if len(sample_news_update) > 800 else sample_news_update)\n",
    "else:\n",
    "    print(\"Fungsi format news update telah disiapkan.\")\n",
    "    print(\"Gunakan: generate_news_update_format(df_analyzed) untuk generate news update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e026da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREVIEW FORMAT LAPORAN ANALISIS LENGKAP ===\n",
      "**Laporan Analisis Media Online dan Media Sosial**\n",
      "Selasa, 30 September 2025\n",
      "\n",
      "=========================================================\n",
      "\n",
      "**EXECUTIVE SUMMARY**\n",
      "=========================================================\n",
      "Periode pemantauan ini mencatat 2 berita penting yang memenuhi kriteria analisis. \n",
      "Dari total tersebut, 1 berita terkait langsung dengan Kementerian Keuangan dan 1 berita terkait isu nasional/internasional.\n",
      "\n",
      "Isu utama yang mendominasi pemberitaan Kemenkeu adalah Lainnya. \n",
      "Secara keseluruhan, tonasi pemberitaan menunjukkan 1 berita positif, \n",
      "1 berita negatif, dan 0 berita netral.\n",
      "\n",
      "Fokus pemerintah pada periode ini terkonsentrasi pada implementasi kebijakan fiskal dan \n",
      "monitoring pelaksanaan program prioritas nasional.\n",
      "\n",
      "=========================================================\n",
      "\n",
      "**MEDIA ONLINE**\n",
      "\n",
      "**Topik Berita:** bantuan sosial, makan bergizi gratis, tax amnesty\n",
      "\n",
      "**Tonasi Berita:** Netral\n",
      "\n",
      "**Pesan Kunci dan Analisis:**\n",
      "\n",
      "**ISU KEMENKEU**\n",
      "1. JAKARTA, KOMPAS.com - Presiden Prab...\n"
     ]
    }
   ],
   "source": [
    "# Format ketiga \n",
    "# Prompt untuk news update\n",
    "\n",
    "\"\"\"Buatlah sebuah dokumen laporan analisis media online dan media sosial dengan struktur dan format sebagai berikut:\n",
    "\n",
    "1. JUDUL DAN TANGGAL\n",
    "\n",
    "Judul utama: \"Laporan Analisis Media Online dan Media Sosial\"\n",
    "Cantumkan hari, tanggal, dan tahun (contoh: Senin, 29 September 2025)\n",
    "2. EXECUTIVE SUMMARY\n",
    "\n",
    "Gunakan pemisah garis seperti =========\n",
    "Ringkasan harus mencakup poin-poin utama dari pemberitaan media online dan isu-isu terkini, termasuk:\n",
    "Isu utama (misal: sidak menteri, kebijakan cukai, revisi UU, dll.)\n",
    "Fokus pemerintah atau kementerian\n",
    "Pernyataan atau kebijakan penting dari pejabat\n",
    "3. MEDIA ONLINE\n",
    "\n",
    "Subjudul: \"Media Online\"\n",
    "Topik Berita: Sebutkan topik-topik utama yang dilaporkan [topik diambil dari config.json \"topic_keywords\"]\n",
    "Tonasi Berita: Tuliskan sentimen (misal: Netral, Positif, Negatif)\n",
    "Pesan Kunci dan Analisis:\n",
    "Bagian ini dibagi menjadi:\n",
    "ISU KEMENKEU (nomor 1, 2, 3, dst. dengan penjelasan singkat)\n",
    "ISU NASIONAL DAN INTERNASIONAL (nomor 1, 2, dst. dengan penjelasan singkat)\n",
    "Kegiatan yang dirujuk: Jelaskan jenis kegiatan (misal: Kegiatan Baru, Tanggal)\n",
    "Narasumber utama yang dirujuk: Tulis \"Belum ada narasumber\" jika tidak disebutkan\n",
    "Daftar Berita: Buat daftar berita dengan format:\n",
    "Nomor. Judul berita\n",
    "[URL]\n",
    "\n",
    "4. FORMAT UMUM\n",
    "\n",
    "Gunakan pemisah halaman seperti ===== Page X =====\n",
    "Gunakan tanda tebal untuk judul dan subjudul\n",
    "Gunakan tanda - untuk poin-poin dalam analisis\n",
    "Pastikan konsistensi penulisan tanggal, nama, dan istilah\"\"\"\n",
    "\n",
    "def categorize_berita(df_berita):\n",
    "    \"\"\"\n",
    "    Kategorikan berita berdasarkan relevansi dengan Kemenkeu\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary dengan kategori berita\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Keywords untuk identifikasi isu Kemenkeu\n",
    "        kemenkeu_keywords = [\n",
    "            'kemenkeu', 'kementerian keuangan', 'menteri keuangan', 'menkeu',\n",
    "            'pajak', 'bea cukai', 'anggaran', 'fiskal', 'apbn', 'apbd',\n",
    "            'sbn', 'obligasi', 'deficit', 'surplus', 'pembiayaan',\n",
    "            'penerimaan negara', 'belanja negara', 'purbaya'\n",
    "        ]\n",
    "        \n",
    "        # Kategorisasi\n",
    "        isu_kemenkeu = []\n",
    "        isu_nasional_internasional = []\n",
    "        \n",
    "        for idx, row in df_berita.iterrows():\n",
    "            # Gabungkan teks untuk analisis\n",
    "            full_text = f\"{row['judul_berita']} {row['artikel_berita_bersih']}\"\n",
    "            full_text_lower = full_text.lower()\n",
    "            \n",
    "            # Cek apakah mengandung keyword Kemenkeu\n",
    "            is_kemenkeu = any(keyword in full_text_lower for keyword in kemenkeu_keywords)\n",
    "            \n",
    "            if is_kemenkeu or row['kategori_isu'] == 'Kemenkeu':\n",
    "                isu_kemenkeu.append(row)\n",
    "            else:\n",
    "                isu_nasional_internasional.append(row)\n",
    "        \n",
    "        return {\n",
    "            'kemenkeu': pd.DataFrame(isu_kemenkeu),\n",
    "            'nasional_internasional': pd.DataFrame(isu_nasional_internasional)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error categorizing berita: {str(e)}\")\n",
    "        return {'kemenkeu': pd.DataFrame(), 'nasional_internasional': df_berita}\n",
    "\n",
    "def extract_narasumber(df_berita):\n",
    "    \"\"\"\n",
    "    Extract narasumber utama dari berita\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita\n",
    "    \n",
    "    Returns:\n",
    "        list: Daftar narasumber yang teridentifikasi\n",
    "    \"\"\"\n",
    "    narasumber_list = []\n",
    "    \n",
    "    for idx, row in df_berita.iterrows():\n",
    "        if pd.notna(row['poin_of_interest']) and row['poin_of_interest'].strip():\n",
    "            narasumber_list.append(row['poin_of_interest'])\n",
    "        elif pd.notna(row['statement_pejabat']) and row['statement_pejabat'].strip():\n",
    "            # Extract nama dari statement (ambil kata pertama yang kapital)\n",
    "            words = row['statement_pejabat'].split()\n",
    "            for word in words[:5]:  # Cek 5 kata pertama\n",
    "                if word.istitle() and len(word) > 3:\n",
    "                    narasumber_list.append(word)\n",
    "                    break\n",
    "    \n",
    "    # Hapus duplikasi dan return unique narasumber\n",
    "    unique_narasumber = list(set(narasumber_list))[:5]  # Ambil max 5\n",
    "    \n",
    "    return unique_narasumber if unique_narasumber else [\"Belum ada narasumber\"]\n",
    "\n",
    "def generate_executive_summary(df_berita, categorized_berita):\n",
    "    \"\"\"\n",
    "    Generate executive summary untuk laporan\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame semua berita\n",
    "        categorized_berita (dict): Berita yang sudah dikategorikan\n",
    "    \n",
    "    Returns:\n",
    "        str: Executive summary text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Identifikasi isu utama\n",
    "        if not categorized_berita['kemenkeu'].empty:\n",
    "            main_kemenkeu_issue = categorized_berita['kemenkeu'].iloc[0]['subtopik_llm']\n",
    "        else:\n",
    "            main_kemenkeu_issue = \"Tidak ada isu Kemenkeu utama\"\n",
    "        \n",
    "        # Hitung statistik\n",
    "        total_berita = len(df_berita)\n",
    "        kemenkeu_count = len(categorized_berita['kemenkeu'])\n",
    "        nasional_count = len(categorized_berita['nasional_internasional'])\n",
    "        \n",
    "        # Sentimen overview\n",
    "        sentiment_summary = generate_sentiment_summary(df_berita)\n",
    "        \n",
    "        # Buat executive summary\n",
    "        executive_summary = f\"\"\"\n",
    "Periode pemantauan ini mencatat {total_berita} berita penting yang memenuhi kriteria analisis. \n",
    "Dari total tersebut, {kemenkeu_count} berita terkait langsung dengan Kementerian Keuangan dan {nasional_count} berita terkait isu nasional/internasional.\n",
    "\n",
    "Isu utama yang mendominasi pemberitaan Kemenkeu adalah {main_kemenkeu_issue}. \n",
    "Secara keseluruhan, tonasi pemberitaan menunjukkan {sentiment_summary['positif']} berita positif, \n",
    "{sentiment_summary['negatif']} berita negatif, dan {sentiment_summary['netral']} berita netral.\n",
    "\n",
    "Fokus pemerintah pada periode ini terkonsentrasi pada implementasi kebijakan fiskal dan \n",
    "monitoring pelaksanaan program prioritas nasional.\n",
    "\"\"\"\n",
    "        \n",
    "        return executive_summary.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating executive summary: {str(e)}\")\n",
    "        return \"Error dalam membuat executive summary\"\n",
    "\n",
    "def generate_laporan_analisis_lengkap(df_berita, periode_start=None, periode_end=None):\n",
    "    \"\"\"\n",
    "    Generate laporan analisis media online dan media sosial lengkap\n",
    "    \n",
    "    Args:\n",
    "        df_berita (pd.DataFrame): DataFrame berita yang sudah dianalisis\n",
    "        periode_start (str): Tanggal mulai periode\n",
    "        periode_end (str): Tanggal akhir periode\n",
    "    \n",
    "    Returns:\n",
    "        str: Laporan lengkap dalam format yang diinginkan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df_berita.empty:\n",
    "            return \"Tidak ada data berita untuk dianalisis.\"\n",
    "        \n",
    "        # Load config\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Header laporan\n",
    "        tanggal_laporan = format_tanggal_indonesia(datetime.now())\n",
    "        \n",
    "        laporan = f\"\"\"**Laporan Analisis Media Online dan Media Sosial**\n",
    "{tanggal_laporan}\n",
    "\n",
    "=========================================================\n",
    "\n",
    "**EXECUTIVE SUMMARY**\n",
    "=========================================================\n",
    "\"\"\"\n",
    "        \n",
    "        # Kategorisasi berita\n",
    "        categorized_berita = categorize_berita(df_berita)\n",
    "        \n",
    "        # Executive Summary\n",
    "        exec_summary = generate_executive_summary(df_berita, categorized_berita)\n",
    "        laporan += exec_summary\n",
    "        \n",
    "        laporan += \"\\n\\n=========================================================\\n\\n\"\n",
    "        \n",
    "        # Section Media Online\n",
    "        laporan += \"**MEDIA ONLINE**\\n\\n\"\n",
    "        \n",
    "        # Topik Berita\n",
    "        topic_keywords = config.get('topic_keywords', [])\n",
    "        topik_text = \", \".join(topic_keywords) if topic_keywords else \"Beragam topik\"\n",
    "        laporan += f\"**Topik Berita:** {topik_text}\\n\\n\"\n",
    "        \n",
    "        # Tonasi Berita\n",
    "        sentiment_summary = generate_sentiment_summary(df_berita)\n",
    "        if sentiment_summary['positif'] > sentiment_summary['negatif']:\n",
    "            tonasi_dominan = \"Positif\"\n",
    "        elif sentiment_summary['negatif'] > sentiment_summary['positif']:\n",
    "            tonasi_dominan = \"Negatif\"\n",
    "        else:\n",
    "            tonasi_dominan = \"Netral\"\n",
    "        \n",
    "        laporan += f\"**Tonasi Berita:** {tonasi_dominan}\\n\\n\"\n",
    "        \n",
    "        # Pesan Kunci dan Analisis\n",
    "        laporan += \"**Pesan Kunci dan Analisis:**\\n\\n\"\n",
    "        \n",
    "        # ISU KEMENKEU\n",
    "        laporan += \"**ISU KEMENKEU**\\n\"\n",
    "        if not categorized_berita['kemenkeu'].empty:\n",
    "            for i, (idx, row) in enumerate(categorized_berita['kemenkeu'].head(5).iterrows(), 1):\n",
    "                if 'ai_resume' in row and pd.notna(row['ai_resume']):\n",
    "                    desc = row['ai_resume']\n",
    "                else:\n",
    "                    desc = row['artikel_berita_bersih'][:200] + \"...\"\n",
    "                laporan += f\"{i}. {desc}\\n\"\n",
    "        else:\n",
    "            laporan += \"1. Tidak ada isu Kemenkeu yang dominan pada periode ini\\n\"\n",
    "        \n",
    "        laporan += \"\\n\"\n",
    "        \n",
    "        # ISU NASIONAL DAN INTERNASIONAL\n",
    "        laporan += \"**ISU NASIONAL DAN INTERNASIONAL**\\n\"\n",
    "        if not categorized_berita['nasional_internasional'].empty:\n",
    "            for i, (idx, row) in enumerate(categorized_berita['nasional_internasional'].head(5).iterrows(), 1):\n",
    "                if 'ai_resume' in row and pd.notna(row['ai_resume']):\n",
    "                    desc = row['ai_resume']\n",
    "                else:\n",
    "                    desc = row['artikel_berita_bersih'][:200] + \"...\"\n",
    "                laporan += f\"{i}. {desc}\\n\"\n",
    "        else:\n",
    "            laporan += \"1. Tidak ada isu nasional/internasional yang signifikan\\n\"\n",
    "        \n",
    "        laporan += \"\\n\"\n",
    "        \n",
    "        # Kegiatan yang dirujuk\n",
    "        laporan += f\"**Kegiatan yang dirujuk:** Kegiatan Pemantauan Berita, {tanggal_laporan}\\n\\n\"\n",
    "        \n",
    "        # Narasumber utama\n",
    "        narasumber_list = extract_narasumber(df_berita)\n",
    "        narasumber_text = \", \".join(narasumber_list[:3]) if len(narasumber_list) > 0 else \"Belum ada narasumber\"\n",
    "        laporan += f\"**Narasumber utama yang dirujuk:** {narasumber_text}\\n\\n\"\n",
    "        \n",
    "        # Daftar Berita\n",
    "        laporan += \"**Daftar Berita:**\\n\"\n",
    "        for i, (idx, row) in enumerate(df_berita.iterrows(), 1):\n",
    "            judul_clean = row['judul_berita'].replace('\\n', ' ').strip()\n",
    "            laporan += f\"{i}. {judul_clean}\\n[{row['url_berita']}]\\n\\n\"\n",
    "        \n",
    "        # Page separator\n",
    "        laporan += \"\\n===== Page 1 =====\\n\"\n",
    "        \n",
    "        return laporan\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating laporan analisis lengkap: {str(e)}\")\n",
    "        return f\"Error dalam generate laporan: {str(e)}\"\n",
    "\n",
    "def save_laporan_analisis_lengkap(laporan_text, output_dir=\"00_laporan_cetak\"):\n",
    "    \"\"\"\n",
    "    Simpan laporan analisis lengkap ke file\n",
    "    \n",
    "    Args:\n",
    "        laporan_text (str): Teks laporan\n",
    "        output_dir (str): Directory output\n",
    "    \n",
    "    Returns:\n",
    "        str: Path file yang disimpan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Buat directory jika belum ada\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        # Nama file dengan timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"laporan_analisis_media_{timestamp}.txt\"\n",
    "        filepath = Path(output_dir) / filename\n",
    "        \n",
    "        # Simpan file\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(laporan_text)\n",
    "        \n",
    "        logger.info(f\"Laporan analisis lengkap disimpan: {filepath}\")\n",
    "        return str(filepath)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving laporan analisis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Test format dengan data dummy jika ada data\n",
    "if 'df_berita_penting' in locals() and not df_berita_penting.empty:\n",
    "    print(\"=== PREVIEW FORMAT LAPORAN ANALISIS LENGKAP ===\")\n",
    "    sample_laporan = generate_laporan_analisis_lengkap(df_berita_penting.head(3))\n",
    "    print(sample_laporan[:1000] + \"...\" if len(sample_laporan) > 1000 else sample_laporan)\n",
    "else:\n",
    "    print(\"Fungsi format laporan analisis lengkap telah disiapkan.\")\n",
    "    print(\"Gunakan: generate_laporan_analisis_lengkap(df_analyzed) untuk generate laporan lengkap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7e5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ PIPELINE ANALISIS BERITA PENTING SIAP!\n",
      "\n",
      "Pilihan penggunaan:\n",
      "\n",
      "1. QUICK PREVIEW (tanpa AI, tanpa save):\n",
      "   quick_preview()\n",
      "\n",
      "2. ANALISIS LENGKAP (dengan AI):\n",
      "   # Dengan OpenAI\n",
      "   results = run_complete_analysis(\n",
      "       ai_provider=\"openai\", \n",
      "       api_key=\"your-openai-api-key\",\n",
      "       save_outputs=True\n",
      "   )\n",
      "   \n",
      "   # Dengan DeepSeek\n",
      "   results = run_complete_analysis(\n",
      "       ai_provider=\"deepseek\", \n",
      "       api_key=\"your-deepseek-api-key\", \n",
      "       save_outputs=True\n",
      "   )\n",
      "\n",
      "3. ANALISIS TANPA AI (hanya format):\n",
      "   results = run_complete_analysis(save_outputs=True)\n",
      "\n",
      "4. FUNGSI INDIVIDUAL:\n",
      "   - load_berita_penting()\n",
      "   - generate_daftar_berita_format(df)\n",
      "   - generate_news_update_format(df)\n",
      "   - generate_laporan_analisis_lengkap(df)\n",
      "\n",
      "Jalankan quick_preview() untuk melihat contoh hasil!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPLEMENTASI LENGKAP PIPELINE ANALISIS BERITA PENTING\n",
    "# =============================================================================\n",
    "\n",
    "def run_complete_analysis(ai_provider=\"openai\", api_key=None, save_outputs=True):\n",
    "    \"\"\"\n",
    "    Menjalankan pipeline lengkap analisis berita penting\n",
    "    \n",
    "    Args:\n",
    "        ai_provider (str): Provider AI (\"openai\" atau \"deepseek\")\n",
    "        api_key (str): API key untuk AI provider  \n",
    "        save_outputs (bool): Simpan output ke file atau tidak\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary berisi semua hasil analisis\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Memulai pipeline analisis berita penting...\")\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Load berita penting\n",
    "        print(\"\\nðŸ“Š Step 1: Loading berita penting...\")\n",
    "        df_berita = load_berita_penting()\n",
    "        \n",
    "        if df_berita.empty:\n",
    "            print(\"âŒ Tidak ada berita penting yang memenuhi kriteria!\")\n",
    "            return {'error': 'No data'}\n",
    "        \n",
    "        print(f\"âœ… Berhasil memuat {len(df_berita)} berita penting\")\n",
    "        results['raw_data'] = df_berita\n",
    "        \n",
    "        # 2. Analisis AI (opsional jika ada API key)\n",
    "        if api_key:\n",
    "            print(f\"\\nðŸ¤– Step 2: Analisis dengan {ai_provider.upper()}...\")\n",
    "            df_analyzed = analyze_berita_batch(df_berita, ai_provider, api_key)\n",
    "            print(\"âœ… Analisis AI selesai\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸  Step 2: Skip analisis AI (tidak ada API key)\")\n",
    "            df_analyzed = df_berita\n",
    "        \n",
    "        results['analyzed_data'] = df_analyzed\n",
    "        \n",
    "        # 3. Generate Format Daftar Berita\n",
    "        print(\"\\nðŸ“‹ Step 3: Generate Daftar Berita...\")\n",
    "        daftar_berita = generate_daftar_berita_format(df_analyzed)\n",
    "        results['daftar_berita'] = daftar_berita\n",
    "        \n",
    "        if save_outputs:\n",
    "            daftar_path = save_daftar_berita(daftar_berita)\n",
    "            results['daftar_berita_file'] = daftar_path\n",
    "            print(f\"âœ… Daftar berita disimpan: {daftar_path}\")\n",
    "        \n",
    "        # 4. Generate News Update\n",
    "        print(\"\\nðŸ“° Step 4: Generate News Update...\")\n",
    "        news_update = generate_news_update_format(df_analyzed)\n",
    "        results['news_update'] = news_update\n",
    "        \n",
    "        if save_outputs:\n",
    "            news_update_path = save_news_update(news_update)\n",
    "            results['news_update_file'] = news_update_path\n",
    "            print(f\"âœ… News update disimpan: {news_update_path}\")\n",
    "        \n",
    "        # 5. Generate Laporan Analisis Lengkap\n",
    "        print(\"\\nðŸ“Š Step 5: Generate Laporan Analisis Lengkap...\")\n",
    "        laporan_lengkap = generate_laporan_analisis_lengkap(df_analyzed)\n",
    "        results['laporan_lengkap'] = laporan_lengkap\n",
    "        \n",
    "        if save_outputs:\n",
    "            laporan_path = save_laporan_analisis_lengkap(laporan_lengkap)\n",
    "            results['laporan_lengkap_file'] = laporan_path\n",
    "            print(f\"âœ… Laporan lengkap disimpan: {laporan_path}\")\n",
    "        \n",
    "        # 6. Summary hasil\n",
    "        print(f\"\\nðŸŽ‰ Pipeline selesai! Summary:\")\n",
    "        print(f\"   - Total berita dianalisis: {len(df_analyzed)}\")\n",
    "        print(f\"   - Sentimen positif: {len(df_analyzed[df_analyzed['sentimen'] == 'positif'])}\")\n",
    "        print(f\"   - Sentimen negatif: {len(df_analyzed[df_analyzed['sentimen'] == 'negatif'])}\")\n",
    "        print(f\"   - Sentimen netral: {len(df_analyzed[df_analyzed['sentimen'] == 'netral'])}\")\n",
    "        \n",
    "        if save_outputs:\n",
    "            print(f\"\\nðŸ“ File output tersimpan di: ./00_laporan_cetak/\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error dalam pipeline: {str(e)}\")\n",
    "        print(f\"âŒ Error: {str(e)}\")\n",
    "        return {'error': str(e)}\n",
    "\n",
    "def quick_preview():\n",
    "    \"\"\"\n",
    "    Quick preview hasil analisis tanpa AI dan tanpa save file\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” Quick Preview Mode...\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        df_berita = load_berita_penting()\n",
    "        \n",
    "        if df_berita.empty:\n",
    "            print(\"âŒ Tidak ada data berita penting\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Data Overview:\")\n",
    "        print(f\"   Total berita: {len(df_berita)}\")\n",
    "        print(f\"   Topik utama: {df_berita['subtopik_llm'].value_counts().head().to_dict()}\")\n",
    "        print(f\"   Sentimen: {df_berita['sentimen'].value_counts().to_dict()}\")\n",
    "        print(f\"   Rata-rata importance: {df_berita['importance'].mean():.1f}\")\n",
    "        \n",
    "        # Preview format\n",
    "        print(f\"\\nðŸ“‹ Preview Daftar Berita (3 teratas):\")\n",
    "        print(\"-\" * 50)\n",
    "        preview_daftar = generate_daftar_berita_format(df_berita.head(3))\n",
    "        print(preview_daftar)\n",
    "        \n",
    "        print(f\"\\nðŸ“° Preview News Update (3 teratas):\")\n",
    "        print(\"-\" * 50)\n",
    "        preview_news = generate_news_update_format(df_berita.head(3))\n",
    "        print(preview_news[:500] + \"...\" if len(preview_news) > 500 else preview_news)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {str(e)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CONTOH PENGGUNAAN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸŽ¯ PIPELINE ANALISIS BERITA PENTING SIAP!\n",
    "\n",
    "Pilihan penggunaan:\n",
    "\n",
    "1. QUICK PREVIEW (tanpa AI, tanpa save):\n",
    "   quick_preview()\n",
    "\n",
    "2. ANALISIS LENGKAP (dengan AI):\n",
    "   # Dengan OpenAI\n",
    "   results = run_complete_analysis(\n",
    "       ai_provider=\"openai\", \n",
    "       api_key=\"your-openai-api-key\",\n",
    "       save_outputs=True\n",
    "   )\n",
    "   \n",
    "   # Dengan DeepSeek\n",
    "   results = run_complete_analysis(\n",
    "       ai_provider=\"deepseek\", \n",
    "       api_key=\"your-deepseek-api-key\", \n",
    "       save_outputs=True\n",
    "   )\n",
    "\n",
    "3. ANALISIS TANPA AI (hanya format):\n",
    "   results = run_complete_analysis(save_outputs=True)\n",
    "\n",
    "4. FUNGSI INDIVIDUAL:\n",
    "   - load_berita_penting()\n",
    "   - generate_daftar_berita_format(df)\n",
    "   - generate_news_update_format(df)\n",
    "   - generate_laporan_analisis_lengkap(df)\n",
    "\n",
    "Jalankan quick_preview() untuk melihat contoh hasil!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a63c1efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:00,314 - INFO - Membaca file analisis AI: 00_hasil_analisis/seluruh_berita/analisis_ai_20250930_deepseek_default.csv\n",
      "2025-09-30 13:41:00,316 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,317 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:00,316 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,317 - INFO - Berita penting (filtered): 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Quick Preview Mode...\n",
      "\n",
      "ðŸ“Š Data Overview:\n",
      "   Total berita: 2\n",
      "   Topik utama: {'Lainnya': 2}\n",
      "   Sentimen: {'positif': 1, 'negatif': 1}\n",
      "   Rata-rata importance: 75.0\n",
      "\n",
      "ðŸ“‹ Preview Daftar Berita (3 teratas):\n",
      "--------------------------------------------------\n",
      "Daftar Berita & Konten\n",
      "Selasa, 30 September 2025\n",
      "Periode pantauan tanggal 29-30 September 2025 (pukul 14.00 s.d. 06.00 WIB)\n",
      "\n",
      "Media Online\n",
      "===========\n",
      "\n",
      "ðŸ”´ [Negatif] Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 Juta Langsung MiskinResearch2 jam yang lalu\n",
      "https://www.cnbcindonesia.com/research/20250929102709-128-670989/rupiah-anjlok-20-vs-real-arab-umroh-bawa-rp-10-juta-langsung-miskin\n",
      "\n",
      "ðŸŸ¢ [Positif] Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilegal di Babel, Selamatkan Rp 22 TriliunNEWS29/09/2025\n",
      "https://nasional.kompas.com/read/2025/09/29/11394051/prabowo-sebut-pemerintah-tutup-1000-tambang-ilegal-di-babel-selamatkan-rp-22\n",
      "\n",
      "\n",
      "\n",
      "ðŸ“° Preview News Update (3 teratas):\n",
      "--------------------------------------------------\n",
      "News Update\n",
      "Lainnya\n",
      "Jakarta, Selasa, 30 September 2025 (Pukul 13.41 WIB)\n",
      "\n",
      "Pemberitaan mengenai lainnya hari ini tercatat terdapat 2 berita (1 positif dan 1 negatif) di media online.\n",
      "\n",
      "Sorotan Media Online\n",
      "â€¢ Presiden Prabowo Subianto\n",
      "â€¢ Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 Juta Langsung Miskin Jakarta, CNBC Indonesia - Tak hanya tertekan terhadap dolar Amerika Serikat (AS)...\n",
      "\n",
      "Tautan Media Online:\n",
      "1. Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilegal di Babel, Selamatkan Rp 22 TriliunN...\n"
     ]
    }
   ],
   "source": [
    "# Test quick preview\n",
    "quick_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c5421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:00,327 - INFO - Membaca file analisis AI: 00_hasil_analisis/seluruh_berita/analisis_ai_20250930_deepseek_default.csv\n",
      "2025-09-30 13:41:00,329 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,330 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:00,330 - INFO - Menganalisis berita 1/2: Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilega...\n",
      "2025-09-30 13:41:00,329 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:00,330 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:00,330 - INFO - Menganalisis berita 1/2: Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilega...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Memulai pipeline analisis berita penting...\n",
      "\n",
      "ðŸ“Š Step 1: Loading berita penting...\n",
      "âœ… Berhasil memuat 2 berita penting\n",
      "\n",
      "ðŸ¤– Step 2: Analisis dengan OPENAI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:05,848 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:05,852 - INFO - âœ… Berhasil menganalisis berita 1\n",
      "2025-09-30 13:41:05,852 - INFO - âœ… Berhasil menganalisis berita 1\n",
      "2025-09-30 13:41:06,858 - INFO - Menganalisis berita 2/2: Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 J...\n",
      "2025-09-30 13:41:06,858 - INFO - Menganalisis berita 2/2: Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 J...\n",
      "2025-09-30 13:41:12,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:12,948 - INFO - âœ… Berhasil menganalisis berita 2\n",
      "2025-09-30 13:41:12,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:12,948 - INFO - âœ… Berhasil menganalisis berita 2\n",
      "2025-09-30 13:41:13,962 - INFO - Laporan daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134113.txt\n",
      "2025-09-30 13:41:13,974 - INFO - News update disimpan: 00_laporan_cetak/news_update_general_20250930_134113.txt\n",
      "2025-09-30 13:41:13,962 - INFO - Laporan daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134113.txt\n",
      "2025-09-30 13:41:13,974 - INFO - News update disimpan: 00_laporan_cetak/news_update_general_20250930_134113.txt\n",
      "2025-09-30 13:41:13,978 - INFO - Laporan analisis lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134113.txt\n",
      "2025-09-30 13:41:13,978 - INFO - Laporan analisis lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134113.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analisis AI selesai\n",
      "\n",
      "ðŸ“‹ Step 3: Generate Daftar Berita...\n",
      "âœ… Daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134113.txt\n",
      "\n",
      "ðŸ“° Step 4: Generate News Update...\n",
      "âœ… News update disimpan: 00_laporan_cetak/news_update_general_20250930_134113.txt\n",
      "\n",
      "ðŸ“Š Step 5: Generate Laporan Analisis Lengkap...\n",
      "âœ… Laporan lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134113.txt\n",
      "\n",
      "ðŸŽ‰ Pipeline selesai! Summary:\n",
      "   - Total berita dianalisis: 2\n",
      "   - Sentimen positif: 1\n",
      "   - Sentimen negatif: 1\n",
      "   - Sentimen netral: 0\n",
      "\n",
      "ðŸ“ File output tersimpan di: ./00_laporan_cetak/\n"
     ]
    }
   ],
   "source": [
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Pipeline lengkap dengan OpenAI\n",
    "results = run_complete_analysis(\n",
    "    ai_provider=\"openai\", \n",
    "    api_key=OPENAI_API_KEY,\n",
    "    save_outputs=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2e50160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing analisis dengan OpenAI API yang telah diperbaiki...\n",
      "âœ… OpenAI API key tersedia\n",
      "\n",
      "ðŸ” Testing analisis 1 berita...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:21,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analisis OpenAI berhasil!\n",
      "ðŸ“Š Sample result:\n",
      "   resume: Presiden Prabowo Subianto mengumumkan penutupan 1.000 tambang ilegal di Bangka Belitung, yang dihara...\n",
      "   dampak_kemenkeu: positif...\n",
      "   alasan_dampak: Penutupan tambang ilegal dapat meningkatkan pendapatan negara dari sektor perpajakan dan kepabeanan,...\n",
      "   hal_menarik: Pernyataan Prabowo menyoroti pentingnya pengawasan terhadap sumber daya alam dan dampaknya terhadap ...\n",
      "\n",
      "ðŸŸ¦ DeepSeek API key tersedia sebagai alternatif\n"
     ]
    }
   ],
   "source": [
    "# Test dengan OpenAI yang sudah diperbaiki\n",
    "print(\"ðŸ§ª Testing analisis dengan OpenAI API yang telah diperbaiki...\")\n",
    "\n",
    "# Cek API key availability\n",
    "if OPENAI_API_KEY and OPENAI_API_KEY.strip():\n",
    "    print(\"âœ… OpenAI API key tersedia\")\n",
    "    \n",
    "    # Test analisis single berita\n",
    "    if not df_berita_penting.empty:\n",
    "        print(f\"\\nðŸ” Testing analisis 1 berita...\")\n",
    "        test_row = df_berita_penting.iloc[0]\n",
    "        \n",
    "        prompt = create_analysis_prompt(\n",
    "            test_row['judul_berita'][:100] + \"...\", \n",
    "            test_row['artikel_berita_bersih'][:500] + \"...\", \n",
    "            test_row['source_domain']\n",
    "        )\n",
    "        \n",
    "        result = analyze_with_openai(prompt, OPENAI_API_KEY)\n",
    "        \n",
    "        if result:\n",
    "            print(\"âœ… Analisis OpenAI berhasil!\")\n",
    "            print(\"ðŸ“Š Sample result:\")\n",
    "            for key, value in result.items():\n",
    "                print(f\"   {key}: {value[:100]}...\")\n",
    "        else:\n",
    "            print(\"âŒ Analisis OpenAI gagal\")\n",
    "    else:\n",
    "        print(\"âŒ Tidak ada data berita untuk di-test\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API key tidak tersedia\")\n",
    "\n",
    "# Alternative: Test dengan DeepSeek jika OpenAI tidak tersedia\n",
    "if DEEPSEEK_API_KEY and DEEPSEEK_API_KEY.strip():\n",
    "    print(\"\\nðŸŸ¦ DeepSeek API key tersedia sebagai alternatif\")\n",
    "else:\n",
    "    print(\"\\nâŒ DeepSeek API key juga tidak tersedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f72a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Debug mode: Melihat response mentah dari OpenAI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:24,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Raw response dari OpenAI:\n",
      "```json\n",
      "{\n",
      "    \"resume\": \"Prabowo Subianto mengumumkan bahwa pemerintah telah menutup 1.000 tambang ilegal di Bangka Belitung, yang diharapkan dapat menyelamatkan potensi kerugian negara sebesar Rp 22 triliun.\",\n",
      "    \"dampak_kemenkeu\": \"positif\",\n",
      "    \"alasan_dampak\": \"Penutupan tambang ilegal dapat meningkatkan pendapatan negara dan mengurangi kerugian akibat praktik ilegal, serta mendukung keberlanjutan lingkungan.\",\n",
      "    \"hal_menarik\": \"Jumlah tambang yang ditutup mencapai 1.000, menunjukkan komitmen pemerintah dalam menegakkan hukum dan perlindungan lingkungan.\"\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… JSON parsing berhasil:\n",
      "{'resume': 'Prabowo Subianto mengumumkan bahwa pemerintah telah menutup 1.000 tambang ilegal di Bangka Belitung, yang diharapkan dapat menyelamatkan potensi kerugian negara sebesar Rp 22 triliun.', 'dampak_kemenkeu': 'positif', 'alasan_dampak': 'Penutupan tambang ilegal dapat meningkatkan pendapatan negara dan mengurangi kerugian akibat praktik ilegal, serta mendukung keberlanjutan lingkungan.', 'hal_menarik': 'Jumlah tambang yang ditutup mencapai 1.000, menunjukkan komitmen pemerintah dalam menegakkan hukum dan perlindungan lingkungan.'}\n"
     ]
    }
   ],
   "source": [
    "# Debug: Lihat response mentah dari OpenAI\n",
    "print(\"ðŸ” Debug mode: Melihat response mentah dari OpenAI...\")\n",
    "\n",
    "if OPENAI_API_KEY and OPENAI_API_KEY.strip() and not df_berita_penting.empty:\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # Initialize client\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Buat prompt sederhana untuk debug\n",
    "    test_row = df_berita_penting.iloc[0]\n",
    "    simple_prompt = f\"\"\"\n",
    "Analisis berita ini dan berikan response dalam format JSON:\n",
    "\n",
    "JUDUL: {test_row['judul_berita'][:200]}\n",
    "\n",
    "Berikan analisis dalam format JSON:\n",
    "{{\n",
    "    \"resume\": \"Ringkasan singkat berita\",\n",
    "    \"dampak_kemenkeu\": \"positif/negatif/netral\",\n",
    "    \"alasan_dampak\": \"Alasan dampak\",\n",
    "    \"hal_menarik\": \"Hal menarik\"\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Anda adalah analis berita. Berikan response dalam format JSON yang valid.\"},\n",
    "                {\"role\": \"user\", \"content\": simple_prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        raw_content = response.choices[0].message.content\n",
    "        print(\"ðŸ“„ Raw response dari OpenAI:\")\n",
    "        print(raw_content)\n",
    "        \n",
    "        # Try to parse JSON\n",
    "        try:\n",
    "            import re\n",
    "            # Extract JSON dari response jika ada teks tambahan\n",
    "            json_match = re.search(r'\\{.*\\}', raw_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group()\n",
    "                result = json.loads(json_str)\n",
    "                print(\"\\nâœ… JSON parsing berhasil:\")\n",
    "                print(result)\n",
    "            else:\n",
    "                print(\"\\nâŒ Tidak ditemukan JSON dalam response\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"\\nâŒ JSON parsing error: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error dalam request ke OpenAI: {e}\")\n",
    "else:\n",
    "    print(\"âŒ Tidak dapat melakukan debug (API key atau data tidak tersedia)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7886172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:24,587 - INFO - Membaca file analisis AI: 00_hasil_analisis/seluruh_berita/analisis_ai_20250930_deepseek_default.csv\n",
      "2025-09-30 13:41:24,591 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:24,591 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:24,592 - INFO - Menganalisis berita 1/2: Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilega...\n",
      "2025-09-30 13:41:24,591 - INFO - Total berita: 10\n",
      "2025-09-30 13:41:24,591 - INFO - Berita penting (filtered): 2\n",
      "2025-09-30 13:41:24,592 - INFO - Menganalisis berita 1/2: Prabowo Sebut Pemerintah Tutup 1.000 Tambang Ilega...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing pipeline lengkap dengan perbaikan...\n",
      "ðŸš€ Memulai pipeline analisis berita penting...\n",
      "\n",
      "ðŸ“Š Step 1: Loading berita penting...\n",
      "âœ… Berhasil memuat 2 berita penting\n",
      "\n",
      "ðŸ¤– Step 2: Analisis dengan OPENAI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:41:31,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:31,186 - INFO - âœ… Berhasil menganalisis berita 1\n",
      "2025-09-30 13:41:31,186 - INFO - âœ… Berhasil menganalisis berita 1\n",
      "2025-09-30 13:41:32,191 - INFO - Menganalisis berita 2/2: Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 J...\n",
      "2025-09-30 13:41:32,191 - INFO - Menganalisis berita 2/2: Rupiah Anjlok 20% vs Real Arab, Umroh Bawa Rp 10 J...\n",
      "2025-09-30 13:41:38,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:38,867 - INFO - âœ… Berhasil menganalisis berita 2\n",
      "2025-09-30 13:41:38,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:41:38,867 - INFO - âœ… Berhasil menganalisis berita 2\n",
      "2025-09-30 13:41:39,877 - INFO - Laporan daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134139.txt\n",
      "2025-09-30 13:41:39,882 - INFO - News update disimpan: 00_laporan_cetak/news_update_general_20250930_134139.txt\n",
      "2025-09-30 13:41:39,885 - INFO - Laporan analisis lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134139.txt\n",
      "2025-09-30 13:41:39,877 - INFO - Laporan daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134139.txt\n",
      "2025-09-30 13:41:39,882 - INFO - News update disimpan: 00_laporan_cetak/news_update_general_20250930_134139.txt\n",
      "2025-09-30 13:41:39,885 - INFO - Laporan analisis lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134139.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analisis AI selesai\n",
      "\n",
      "ðŸ“‹ Step 3: Generate Daftar Berita...\n",
      "âœ… Daftar berita disimpan: 00_laporan_cetak/daftar_berita_20250930_134139.txt\n",
      "\n",
      "ðŸ“° Step 4: Generate News Update...\n",
      "âœ… News update disimpan: 00_laporan_cetak/news_update_general_20250930_134139.txt\n",
      "\n",
      "ðŸ“Š Step 5: Generate Laporan Analisis Lengkap...\n",
      "âœ… Laporan lengkap disimpan: 00_laporan_cetak/laporan_analisis_media_20250930_134139.txt\n",
      "\n",
      "ðŸŽ‰ Pipeline selesai! Summary:\n",
      "   - Total berita dianalisis: 2\n",
      "   - Sentimen positif: 1\n",
      "   - Sentimen negatif: 1\n",
      "   - Sentimen netral: 0\n",
      "\n",
      "ðŸ“ File output tersimpan di: ./00_laporan_cetak/\n",
      "\n",
      "ðŸŽ‰ Pipeline berhasil dijalankan!\n",
      "\n",
      "ðŸ“Š Hasil analisis AI:\n",
      "   Kolom AI yang ditambahkan: ['ai_resume', 'ai_dampak_kemenkeu', 'ai_alasan_dampak', 'ai_hal_menarik']\n",
      "\n",
      "ðŸ“ Sample analisis berita pertama:\n",
      "   Resume: Presiden Prabowo Subianto mengumumkan penutupan 1.000 tambang timah ilegal di Bangka Belitung, yang ...\n",
      "   Dampak Kemenkeu: positif\n",
      "   Alasan: Penutupan tambang ilegal dan penghentian penyelundupan timah dapat meningkatkan pendapatan negara da...\n",
      "\n",
      "ðŸ“ File output:\n",
      "   daftar_berita_file: 00_laporan_cetak/daftar_berita_20250930_134139.txt\n",
      "   news_update_file: 00_laporan_cetak/news_update_general_20250930_134139.txt\n",
      "   laporan_lengkap_file: 00_laporan_cetak/laporan_analisis_media_20250930_134139.txt\n"
     ]
    }
   ],
   "source": [
    "# Test final: Pipeline lengkap dengan perbaikan\n",
    "print(\"ðŸš€ Testing pipeline lengkap dengan perbaikan...\")\n",
    "\n",
    "# Jalankan pipeline lengkap\n",
    "results_fixed = run_complete_analysis(\n",
    "    ai_provider=\"openai\", \n",
    "    api_key=OPENAI_API_KEY,\n",
    "    save_outputs=True\n",
    ")\n",
    "\n",
    "# Tampilkan summary hasil\n",
    "if 'error' not in results_fixed:\n",
    "    print(\"\\nðŸŽ‰ Pipeline berhasil dijalankan!\")\n",
    "    \n",
    "    analyzed_df = results_fixed.get('analyzed_data')\n",
    "    if analyzed_df is not None and not analyzed_df.empty:\n",
    "        print(f\"\\nðŸ“Š Hasil analisis AI:\")\n",
    "        ai_columns = [col for col in analyzed_df.columns if col.startswith('ai_')]\n",
    "        if ai_columns:\n",
    "            print(f\"   Kolom AI yang ditambahkan: {ai_columns}\")\n",
    "            \n",
    "            # Show sample AI analysis\n",
    "            first_analysis = analyzed_df.iloc[0]\n",
    "            print(f\"\\nðŸ“ Sample analisis berita pertama:\")\n",
    "            print(f\"   Resume: {first_analysis.get('ai_resume', 'N/A')[:100]}...\")\n",
    "            print(f\"   Dampak Kemenkeu: {first_analysis.get('ai_dampak_kemenkeu', 'N/A')}\")\n",
    "            print(f\"   Alasan: {first_analysis.get('ai_alasan_dampak', 'N/A')[:100]}...\")\n",
    "        else:\n",
    "            print(\"   âš ï¸  Tidak ada kolom AI yang ditambahkan\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ File output:\")\n",
    "    for key, value in results_fixed.items():\n",
    "        if key.endswith('_file'):\n",
    "            print(f\"   {key}: {value}\")\n",
    "            \n",
    "else:\n",
    "    print(f\"âŒ Pipeline gagal: {results_fixed.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4e8f4",
   "metadata": {},
   "source": [
    "## âœ… PERBAIKAN ERROR COMPLETED\n",
    "\n",
    "**Error yang diperbaiki:**\n",
    "1. **OpenAI API v1.0+ Compatibility** - Updated dari `openai.ChatCompletion.create()` ke `client.chat.completions.create()`\n",
    "2. **JSON Parsing Error** - Menambahkan fungsi `parse_ai_response()` untuk handle markdown code blocks (```json)\n",
    "3. **DataFrame Index Handling** - Memperbaiki indexing untuk batch analysis\n",
    "4. **Error Handling** - Improved error logging dan fallback mechanisms\n",
    "\n",
    "**Status:** ðŸŸ¢ **SEMUA FUNGSI BERJALAN NORMAL**\n",
    "\n",
    "**Output yang dihasilkan:**\n",
    "- âœ… Daftar Berita dengan emoji sentimen\n",
    "- âœ… News Update dengan topik dan statistik\n",
    "- âœ… Laporan Analisis Lengkap dengan kategorisasi\n",
    "- âœ… Analisis AI yang berhasil untuk semua berita"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
