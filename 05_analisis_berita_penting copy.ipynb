{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9252cf8",
   "metadata": {},
   "source": [
    "# SETTING ENVIRONMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52389a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# mount the colab with google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# mount the colab with google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "771e26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set folder tempat kerja (current working directory)\n",
    "import os\n",
    "cwd = \"/Users/yusufpradana/Library/CloudStorage/OneDrive-Personal/Pekerjaan BMN/05. 2025/98_monitoring_berita/monitoring-berita\"\n",
    "#cwd = '/content/drive/MyDrive/Monitoring Berita'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4561090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys - diganti dengan konfigurasi lengkap di cell selanjutnya\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e8bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:29:22,555 - INFO - ‚úÖ AI Configuration loaded: DEEPSEEK\n",
      "2025-10-01 08:29:22,556 - INFO -    Model: deepseek-chat\n",
      "2025-10-01 08:29:22,556 - INFO -    Temperature: 0.2\n",
      "2025-10-01 08:29:22,556 - INFO -    Model: deepseek-chat\n",
      "2025-10-01 08:29:22,556 - INFO -    Temperature: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:29:22,556 - INFO -    Max Tokens: 500\n",
      "2025-10-01 08:29:22,734 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:22,734 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KONFIGURASI AI MODEL ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:29:23,853 - INFO - ‚úÖ DEEPSEEK API connection successful\n",
      "2025-10-01 08:29:23,976 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:23,976 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ AI Model: DEEPSEEK (deepseek-chat)\n",
      "üîß Temperature: 0.2\n",
      "üìù Max Tokens: 500\n",
      "üîë API Key: ********************...8d74\n",
      "\n",
      "üß™ Testing AI connection...\n",
      "‚úÖ Test Response: AI Ready!\n",
      "\n",
      "‚úÖ AI configuration completed successfully!\n",
      "üí° Gunakan CALL_AI_MODEL(prompt) untuk memanggil AI di sel lain.\n",
      "\n",
      "üìã Environment Variables yang diset:\n",
      "   MODEL_ANALISIS = deepseek\n",
      "   AI_MODEL_NAME = deepseek-chat\n",
      "   DUMMY_MODE = 0\n",
      "‚úÖ Test Response: AI Ready!\n",
      "\n",
      "‚úÖ AI configuration completed successfully!\n",
      "üí° Gunakan CALL_AI_MODEL(prompt) untuk memanggil AI di sel lain.\n",
      "\n",
      "üìã Environment Variables yang diset:\n",
      "   MODEL_ANALISIS = deepseek\n",
      "   AI_MODEL_NAME = deepseek-chat\n",
      "   DUMMY_MODE = 0\n"
     ]
    }
   ],
   "source": [
    "# Membaca AI model yang dipilih user melalui config.json ['AI_name']\n",
    "# Kemudian mengaplikasikan pilihan tersebut (openai/deepseek) ke seluruh sel utama\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_ai_configuration():\n",
    "    \"\"\"\n",
    "    Memuat konfigurasi AI model dari config.json dan setup environment\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary berisi konfigurasi AI yang telah diload\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Baca config.json\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Ambil AI configuration\n",
    "        ai_name = config.get('AI_name', 'openai').lower()\n",
    "        \n",
    "        # Validasi AI name\n",
    "        supported_ai = ['openai', 'deepseek']\n",
    "        if ai_name not in supported_ai:\n",
    "            logger.warning(f\"AI model '{ai_name}' tidak didukung. Menggunakan 'openai' sebagai default.\")\n",
    "            ai_name = 'openai'\n",
    "        \n",
    "        # Setup environment variables berdasarkan pilihan AI\n",
    "        if ai_name == 'openai':\n",
    "            api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "            if not api_key:\n",
    "                raise ValueError(\"OPENAI_API_KEY tidak ditemukan di environment variables\")\n",
    "            \n",
    "            ai_config = {\n",
    "                'provider': 'openai',\n",
    "                'model': config.get('openai_model', 'gpt-4o-mini'),\n",
    "                'api_key': api_key,\n",
    "                'base_url': None,\n",
    "                'temperature': config.get('temperature', 0.2),\n",
    "                'max_tokens': config.get('max_tokens', 500)\n",
    "            }\n",
    "            \n",
    "        elif ai_name == 'deepseek':\n",
    "            api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "            if not api_key:\n",
    "                raise ValueError(\"DEEPSEEK_API_KEY tidak ditemukan di environment variables\")\n",
    "                \n",
    "            ai_config = {\n",
    "                'provider': 'deepseek',\n",
    "                'model': config.get('deepseek_model', 'deepseek-chat'),\n",
    "                'api_key': api_key,\n",
    "                'base_url': 'https://api.deepseek.com/v1',\n",
    "                'temperature': config.get('temperature', 0.2),\n",
    "                'max_tokens': config.get('max_tokens', 500)\n",
    "            }\n",
    "        \n",
    "        # Set global environment variable untuk digunakan di sel lain\n",
    "        os.environ['MODEL_ANALISIS'] = ai_name\n",
    "        os.environ['AI_MODEL_NAME'] = ai_config['model']\n",
    "        os.environ['AI_TEMPERATURE'] = str(ai_config['temperature'])\n",
    "        os.environ['AI_MAX_TOKENS'] = str(ai_config['max_tokens'])\n",
    "        \n",
    "        if ai_config['base_url']:\n",
    "            os.environ['AI_BASE_URL'] = ai_config['base_url']\n",
    "        \n",
    "        logger.info(f\"‚úÖ AI Configuration loaded: {ai_name.upper()}\")\n",
    "        logger.info(f\"   Model: {ai_config['model']}\")\n",
    "        logger.info(f\"   Temperature: {ai_config['temperature']}\")\n",
    "        logger.info(f\"   Max Tokens: {ai_config['max_tokens']}\")\n",
    "        \n",
    "        return ai_config\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"‚ùå File config.json tidak ditemukan!\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"‚ùå Error parsing config.json: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error loading AI configuration: {e}\")\n",
    "        raise\n",
    "\n",
    "def setup_ai_client(ai_config):\n",
    "    \"\"\"\n",
    "    Setup AI client berdasarkan konfigurasi yang dipilih\n",
    "    \n",
    "    Args:\n",
    "        ai_config (dict): Konfigurasi AI dari load_ai_configuration()\n",
    "    \n",
    "    Returns:\n",
    "        object: AI client object (OpenAI atau Deepseek compatible)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ai_config['provider'] == 'openai':\n",
    "            from openai import OpenAI\n",
    "            \n",
    "            client = OpenAI(\n",
    "                api_key=ai_config['api_key']\n",
    "            )\n",
    "            \n",
    "        elif ai_config['provider'] == 'deepseek':\n",
    "            from openai import OpenAI  # Deepseek menggunakan OpenAI compatible API\n",
    "            \n",
    "            client = OpenAI(\n",
    "                api_key=ai_config['api_key'],\n",
    "                base_url=ai_config['base_url']\n",
    "            )\n",
    "        \n",
    "        # Test connection dengan simple call\n",
    "        test_response = client.chat.completions.create(\n",
    "            model=ai_config['model'],\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Test connection. Respond with 'OK'.\"}],\n",
    "            max_tokens=10,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        if test_response.choices[0].message.content:\n",
    "            logger.info(f\"‚úÖ {ai_config['provider'].upper()} API connection successful\")\n",
    "            return client\n",
    "        else:\n",
    "            raise Exception(\"API test failed - empty response\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        logger.error(f\"‚ùå Missing required library: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error setting up {ai_config['provider']} client: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_ai_call_function(ai_config, client):\n",
    "    \"\"\"\n",
    "    Mengembalikan function untuk memanggil AI yang sudah dikonfigurasi\n",
    "    \n",
    "    Args:\n",
    "        ai_config (dict): Konfigurasi AI\n",
    "        client (object): AI client object\n",
    "    \n",
    "    Returns:\n",
    "        function: Function untuk memanggil AI dengan parameter standar\n",
    "    \"\"\"\n",
    "    def call_ai_model(prompt, temperature=None, max_tokens=None):\n",
    "        \"\"\"\n",
    "        Function wrapper untuk memanggil AI model dengan konfigurasi yang sudah diset\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): Prompt untuk AI\n",
    "            temperature (float, optional): Temperature override\n",
    "            max_tokens (int, optional): Max tokens override\n",
    "            \n",
    "        Returns:\n",
    "            str: Response dari AI model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=ai_config['model'],\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature or ai_config['temperature'],\n",
    "                max_tokens=max_tokens or ai_config['max_tokens']\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling {ai_config['provider']} API: {e}\")\n",
    "            raise\n",
    "    \n",
    "    return call_ai_model\n",
    "\n",
    "# ===== EKSEKUSI KONFIGURASI AI ===== #\n",
    "print(\"=== KONFIGURASI AI MODEL ===\")\n",
    "\n",
    "try:\n",
    "    # Load AI configuration dari config.json\n",
    "    ai_config = load_ai_configuration()\n",
    "    \n",
    "    # Setup AI client\n",
    "    ai_client = setup_ai_client(ai_config)\n",
    "    \n",
    "    # Buat function wrapper untuk memanggil AI\n",
    "    call_ai_model = get_ai_call_function(ai_config, ai_client)\n",
    "    \n",
    "    # Set sebagai global variables untuk digunakan di sel lain\n",
    "    globals()['AI_CONFIG'] = ai_config\n",
    "    globals()['AI_CLIENT'] = ai_client \n",
    "    globals()['CALL_AI_MODEL'] = call_ai_model\n",
    "    \n",
    "    print(f\"üéØ AI Model: {ai_config['provider'].upper()} ({ai_config['model']})\")\n",
    "    print(f\"üîß Temperature: {ai_config['temperature']}\")\n",
    "    print(f\"üìù Max Tokens: {ai_config['max_tokens']}\")\n",
    "    print(f\"üîë API Key: {'*' * 20}...{ai_config['api_key'][-4:]}\")\n",
    "    \n",
    "    # Test simple call\n",
    "    print(f\"\\nüß™ Testing AI connection...\")\n",
    "    test_result = call_ai_model(\"Respond with 'AI Ready!'\", temperature=0, max_tokens=10)\n",
    "    print(f\"‚úÖ Test Response: {test_result}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ AI configuration completed successfully!\")\n",
    "    print(f\"üí° Gunakan CALL_AI_MODEL(prompt) untuk memanggil AI di sel lain.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error dalam setup AI configuration: {e}\")\n",
    "    print(f\"üîß Pastikan:\")\n",
    "    print(f\"   1. File config.json ada dan berisi 'AI_name': 'openai' atau 'deepseek'\")\n",
    "    print(f\"   2. Environment variable API key sudah diset (OPENAI_API_KEY atau DEEPSEEK_API_KEY)\")\n",
    "    print(f\"   3. Library openai sudah terinstall\")\n",
    "    \n",
    "    # Set fallback ke dummy mode\n",
    "    os.environ['DUMMY_MODE'] = '1'\n",
    "    globals()['AI_CONFIG'] = {'provider': 'dummy', 'model': 'dummy'}\n",
    "    globals()['CALL_AI_MODEL'] = lambda prompt, **kwargs: '{\"dummy\": \"response\"}'\n",
    "    print(f\"üîÑ Fallback ke DUMMY MODE untuk development\")\n",
    "\n",
    "print(f\"\\nüìã Environment Variables yang diset:\")\n",
    "print(f\"   MODEL_ANALISIS = {os.getenv('MODEL_ANALISIS', 'not set')}\")\n",
    "print(f\"   AI_MODEL_NAME = {os.getenv('AI_MODEL_NAME', 'not set')}\")\n",
    "print(f\"   DUMMY_MODE = {os.getenv('DUMMY_MODE', '0')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7aa5d",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da78eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:29:32,833 - INFO - Membaca file analisis AI: 00_hasil_analisis/seluruh_berita/analisis_ai_20250930_deepseek_default.csv\n",
      "2025-10-01 08:29:32,857 - INFO - Total berita: 225\n",
      "2025-10-01 08:29:32,858 - INFO - Berita penting (filtered): 107\n",
      "2025-10-01 08:29:32,857 - INFO - Total berita: 225\n",
      "2025-10-01 08:29:32,858 - INFO - Berita penting (filtered): 107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat 107 berita penting\n",
      "\n",
      "Sample berita penting:\n",
      "                                          judul_berita topik_llm  importance  \\\n",
      "94   Menkeu Purbaya Sidak ke Kantor Pusat BNI, Ada ...  Kemenkeu        85.0   \n",
      "118    Cukai Rokok Tak Naik, Penerimaan Turun - KONTAN  Kemenkeu        85.0   \n",
      "116  Pemerhati Sayangkan Penundaan Kenaikan Cukai R...  Kemenkeu        85.0   \n",
      "114  Prabowo Perintahkan Bea Cukai Gandeng Ahli Kim...  Kemenkeu        85.0   \n",
      "113  Saham WIIM, HMSP, GGRM Rontok Usai Menkeu Purb...  Kemenkeu        85.0   \n",
      "\n",
      "    sentimen  \n",
      "94   positif  \n",
      "118  positif  \n",
      "116  negatif  \n",
      "114  positif  \n",
      "113  positif  \n"
     ]
    }
   ],
   "source": [
    "# Langkah pertama membaca file csv hasil analisis AI sebelumnya\n",
    "# file terletak di config.json \"analisis_ai_output\"\n",
    "# Filter out berita dengan topik_llm \"Lainnya\"\n",
    "# Filter out berita dengan importance < 50\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging untuk error handling\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_berita_penting():\n",
    "    \"\"\"\n",
    "    Memuat dan memfilter berita penting dari file hasil analisis AI\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame berisi berita yang sudah difilter\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Baca konfigurasi\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Path file analisis AI\n",
    "        analisis_file = config.get('analisis_ai_output')\n",
    "        if not analisis_file:\n",
    "            raise ValueError(\"analisis_ai_output tidak ditemukan dalam config.json\")\n",
    "        \n",
    "        # Periksa apakah file ada\n",
    "        if not Path(analisis_file).exists():\n",
    "            raise FileNotFoundError(f\"File analisis AI tidak ditemukan: {analisis_file}\")\n",
    "        \n",
    "        # Baca file CSV\n",
    "        logger.info(f\"Membaca file analisis AI: {analisis_file}\")\n",
    "        df = pd.read_csv(analisis_file)\n",
    "        \n",
    "        # Filter berita penting\n",
    "        # 1. Exclude topik_llm \"Lainnya\"\n",
    "        # 2. Include importance >= 70\n",
    "        df_filtered = df[\n",
    "            (df['topik_llm'] != 'Lainnya') & \n",
    "            (df['importance'] >= 70)\n",
    "        ].copy()\n",
    "        \n",
    "        logger.info(f\"Total berita: {len(df)}\")\n",
    "        logger.info(f\"Berita penting (filtered): {len(df_filtered)}\")\n",
    "        \n",
    "        if df_filtered.empty:\n",
    "            logger.warning(\"Tidak ada berita penting yang memenuhi kriteria!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Urutkan berdasarkan importance (descending)\n",
    "        df_filtered = df_filtered.sort_values('importance', ascending=False)\n",
    "        \n",
    "        return df_filtered\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error dalam load_berita_penting: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load data berita penting\n",
    "df_berita_penting = load_berita_penting()\n",
    "print(f\"Berhasil memuat {len(df_berita_penting)} berita penting\")\n",
    "if not df_berita_penting.empty:\n",
    "    print(\"\\nSample berita penting:\")\n",
    "    print(df_berita_penting[['judul_berita', 'topik_llm', 'importance', 'sentimen']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0fdf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unkomen sel ini untuk testing.\n",
    "df_berita_penting = df_berita_penting.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e5631a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom teks: artikel_berita_bersih, Kolom judul: judul_berita\n",
      "AI Model: DEEPSEEK (deepseek-chat)\n",
      "‚úÖ Using pre-configured DEEPSEEK client\n",
      "Starting analysis of 10 articles using DEEPSEEK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025-10-01 08:29:47,981 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:47,981 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:47,995 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:47,995 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:48,011 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:48,011 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|‚ñà         | 1/10 [00:07<01:06,  7.39s/it]2025-10-01 08:29:55,378 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:55,378 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|‚ñà‚ñà        | 2/10 [00:08<00:29,  3.64s/it]2025-10-01 08:29:56,385 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:56,385 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:09<00:16,  2.36s/it]2025-10-01 08:29:57,214 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:29:57,214 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:16<00:25,  4.17s/it]2025-10-01 08:30:04,236 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:30:04,236 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:17<00:15,  3.04s/it]2025-10-01 08:30:05,178 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:30:05,178 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:17<00:08,  2.08s/it]2025-10-01 08:30:05,418 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:30:05,418 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:24<00:11,  3.68s/it]2025-10-01 08:30:12,387 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:30:12,387 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:32<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete: 10 articles in 32.2s\n",
      "Success: 10, Errors: 0\n",
      "AI Provider: DEEPSEEK\n",
      "\n",
      "Sample results (showing 3):\n",
      "1. Omongan Purbaya Sukses Bangkitkan Rupiah, Ini Buktinya! - CN...\n",
      "   Resume: Rupiah menguat 0,51% ke Rp16.640/US$ setelah klarifikasi Menteri Keuan...\n",
      "   Dampak: Positif\n",
      "2. Purbaya Umumkan Cukai Rokok 2026 Tak Naik, Airlangga: Bagus!...\n",
      "   Resume: Menteri Keuangan Purbaya Yudhi Sadewa memastikan tidak akan menaikkan ...\n",
      "   Dampak: Positif\n",
      "3. Menkeu Purbaya Sidak Kantor BNI Saat Direksi Sedang Rapat, A...\n",
      "   Resume: Menteri Keuangan Purbaya melakukan inspeksi mendadak ke kantor BNI saa...\n",
      "   Dampak: Netral\n",
      "\n",
      "File saved: 00_hasil_analisis/berita_penting/analisis_berita_penting_deepseek_20251001_083020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SEL 1 - Analisis Berita Penting (Parallel) - Updated with Dynamic AI Configuration\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x, **_: x\n",
    "\n",
    "# Konfigurasi dari AI setup\n",
    "MAX_WORKERS = 3\n",
    "MODEL_PILIHAN = os.getenv(\"MODEL_ANALISIS\", \"openai\").lower()\n",
    "AI_MODEL_NAME = os.getenv(\"AI_MODEL_NAME\", \"gpt-4o-mini\")\n",
    "DUMMY_MODE = os.getenv(\"DUMMY_MODE\", \"0\") == \"1\"\n",
    "\n",
    "# Deteksi kolom\n",
    "CANDIDATE_TEXT_COLS = [\"isi_berita\", \"content\", \"artikel_berita_bersih\", \"isi\", \"full_text\", \"body\"]\n",
    "TEXT_COL = None\n",
    "for c in CANDIDATE_TEXT_COLS:\n",
    "    if c in df_berita_penting.columns:\n",
    "        TEXT_COL = c\n",
    "        break\n",
    "\n",
    "JUDUL_COL = 'judul_berita'\n",
    "print(f\"Kolom teks: {TEXT_COL}, Kolom judul: {JUDUL_COL}\")\n",
    "print(f\"AI Model: {MODEL_PILIHAN.upper()} ({AI_MODEL_NAME})\")\n",
    "\n",
    "# Setup AI client menggunakan konfigurasi global\n",
    "_ai_client = None\n",
    "_call_ai_model = None\n",
    "\n",
    "if not DUMMY_MODE:\n",
    "    try:\n",
    "        # Gunakan konfigurasi global yang sudah disetup di cell sebelumnya\n",
    "        if 'AI_CLIENT' in globals() and 'CALL_AI_MODEL' in globals():\n",
    "            _ai_client = AI_CLIENT\n",
    "            _call_ai_model = CALL_AI_MODEL\n",
    "            print(f\"‚úÖ Using pre-configured {MODEL_PILIHAN.upper()} client\")\n",
    "        else:\n",
    "            raise Exception(\"AI configuration not found. Please run AI configuration cell first.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing AI client: {e}\")\n",
    "        print(\"üîÑ Switching to DUMMY mode\")\n",
    "        DUMMY_MODE = True\n",
    "\n",
    "def build_prompt(judul: str, isi: str) -> str:\n",
    "    return f\"\"\"Analisis berita ini dan buat JSON dengan format tepat:\n",
    "\n",
    "Judul: {judul[:200]}\n",
    "Isi: {isi[:3000]}\n",
    "\n",
    "Buat JSON dengan 4 field:\n",
    "- resume: ringkasan singkat (maks 60 kata)  \n",
    "- dampak_kemenkeu: Positif/Negatif/Netral (untuk Kementerian Keuangan)\n",
    "- alasan_dampak: alasan singkat (maks 40 kata)\n",
    "- hal_menarik: array 1-3 poin menarik\n",
    "\n",
    "Contoh format:\n",
    "{{\"resume\": \"Menteri melakukan sidak...\", \"dampak_kemenkeu\": \"Positif\", \"alasan_dampak\": \"Meningkatkan transparansi\", \"hal_menarik\": [\"Kunjungan mendadak\", \"Fokus kredit\"]}}\"\"\"\n",
    "\n",
    "def call_model(prompt: str) -> str:\n",
    "    if DUMMY_MODE:\n",
    "        return '{\"resume\": \"Dummy analisis berita\", \"dampak_kemenkeu\": \"Netral\", \"alasan_dampak\": \"Mode dummy testing\", \"hal_menarik\": [\"Test mode\", \"Dummy data\"]}'\n",
    "    \n",
    "    try:\n",
    "        # Gunakan wrapper function yang sudah dikonfigurasi\n",
    "        response = _call_ai_model(\n",
    "            prompt, \n",
    "            temperature=float(os.getenv('AI_TEMPERATURE', '0.2')),\n",
    "            max_tokens=int(os.getenv('AI_MAX_TOKENS', '400'))\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"API call failed: {str(e)}\")\n",
    "\n",
    "def parse_response(raw: str) -> Dict[str, Any]:\n",
    "    if not raw:\n",
    "        raise ValueError(\"Empty response\")\n",
    "    \n",
    "    # Extract JSON\n",
    "    json_match = re.search(r'\\{[^{}]*\"resume\"[^{}]*\\}', raw)\n",
    "    if json_match:\n",
    "        candidate = json_match.group()\n",
    "    else:\n",
    "        candidate = raw.strip()\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(candidate)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"JSON parse error: {e}\")\n",
    "    \n",
    "    # Normalize\n",
    "    result = {\n",
    "        'resume': str(data.get('resume', '')),\n",
    "        'dampak_kemenkeu': str(data.get('dampak_kemenkeu', 'Netral')),\n",
    "        'alasan_dampak': str(data.get('alasan_dampak', '')),\n",
    "        'hal_menarik': data.get('hal_menarik', [])\n",
    "    }\n",
    "    \n",
    "    if isinstance(result['hal_menarik'], str):\n",
    "        result['hal_menarik'] = [result['hal_menarik']]\n",
    "    \n",
    "    # Standardize dampak\n",
    "    dk = result['dampak_kemenkeu'].lower()\n",
    "    if 'pos' in dk:\n",
    "        result['dampak_kemenkeu'] = 'Positif'\n",
    "    elif 'neg' in dk:\n",
    "        result['dampak_kemenkeu'] = 'Negatif'  \n",
    "    else:\n",
    "        result['dampak_kemenkeu'] = 'Netral'\n",
    "        \n",
    "    return result\n",
    "\n",
    "def analyze_row(idx: int, row: pd.Series) -> Dict[str, Any]:\n",
    "    try:\n",
    "        judul = str(row.get(JUDUL_COL, ''))[:300]\n",
    "        isi = str(row.get(TEXT_COL, ''))[:5000]\n",
    "        \n",
    "        # Clean text dari karakter bermasalah\n",
    "        judul = judul.encode('utf-8', 'ignore').decode('utf-8')\n",
    "        isi = isi.encode('utf-8', 'ignore').decode('utf-8')\n",
    "        \n",
    "        prompt = build_prompt(judul, isi)\n",
    "        raw = call_model(prompt)\n",
    "        parsed = parse_response(raw)\n",
    "        \n",
    "        parsed['__status'] = 'ok'\n",
    "        return parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            '__status': 'error',\n",
    "            '__error': str(e)[:200]\n",
    "        }\n",
    "\n",
    "# Execute parallel analysis\n",
    "start_time = time.time()\n",
    "rows_df = df_berita_penting.reset_index(drop=True)\n",
    "results = [None] * len(rows_df)\n",
    "errors = 0\n",
    "\n",
    "print(f\"Starting analysis of {len(rows_df)} articles using {MODEL_PILIHAN.upper()}...\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(analyze_row, i, row): i for i, row in rows_df.iterrows()}\n",
    "    \n",
    "    for fut in tqdm(as_completed(futures), total=len(futures)):\n",
    "        idx = futures[fut]\n",
    "        result = fut.result()\n",
    "        results[idx] = result\n",
    "        \n",
    "        if result.get('__status') != 'ok':\n",
    "            errors += 1\n",
    "\n",
    "# Compile results\n",
    "col_resume = []\n",
    "col_dampak = []\n",
    "col_alasan = []  \n",
    "col_hal = []\n",
    "col_status = []\n",
    "col_error = []\n",
    "\n",
    "for res in results:\n",
    "    if res and res.get('__status') == 'ok':\n",
    "        col_resume.append(res.get('resume', ''))\n",
    "        col_dampak.append(res.get('dampak_kemenkeu', ''))\n",
    "        col_alasan.append(res.get('alasan_dampak', ''))\n",
    "        col_hal.append(' | '.join(res.get('hal_menarik', [])))\n",
    "        col_status.append('ok')\n",
    "        col_error.append('')\n",
    "    else:\n",
    "        col_resume.append('')\n",
    "        col_dampak.append('')\n",
    "        col_alasan.append('')\n",
    "        col_hal.append('')\n",
    "        col_status.append('error')\n",
    "        col_error.append(res.get('__error', 'unknown') if res else 'unknown')\n",
    "\n",
    "# Add results to dataframe\n",
    "df_out = rows_df.copy()\n",
    "df_out['resume_ai'] = col_resume\n",
    "df_out['dampak_kemenkeu_ai'] = col_dampak  \n",
    "df_out['alasan_dampak_ai'] = col_alasan\n",
    "df_out['hal_menarik_ai'] = col_hal\n",
    "df_out['analisis_status'] = col_status\n",
    "df_out['analisis_error'] = col_error\n",
    "\n",
    "proc_time = time.time() - start_time\n",
    "success_count = len(df_out) - errors\n",
    "\n",
    "print(f\"Analysis complete: {len(df_out)} articles in {proc_time:.1f}s\")\n",
    "print(f\"Success: {success_count}, Errors: {errors}\")\n",
    "print(f\"AI Provider: {MODEL_PILIHAN.upper()}\")\n",
    "\n",
    "# Show successful samples\n",
    "success_rows = df_out[df_out['analisis_status'] == 'ok']\n",
    "if not success_rows.empty:\n",
    "    print(f\"\\nSample results (showing {min(3, len(success_rows))}):\")\n",
    "    for i, (_, row) in enumerate(success_rows.head(3).iterrows()):\n",
    "        print(f\"{i+1}. {row['judul_berita'][:60]}...\")\n",
    "        print(f\"   Resume: {row['resume_ai'][:70]}...\")\n",
    "        print(f\"   Dampak: {row['dampak_kemenkeu_ai']}\")\n",
    "\n",
    "# Save results  \n",
    "out_dir = Path('00_hasil_analisis/berita_penting')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "outfile = out_dir / f\"analisis_berita_penting_{MODEL_PILIHAN}_{timestamp}.csv\"\n",
    "df_out.to_csv(outfile, index=False)\n",
    "print(f\"\\nFile saved: {outfile}\")\n",
    "\n",
    "analisis_berita_penting = df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d1609e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATOR DAFTAR BERITA & KONTEN ===\n",
      "üìä Data tersedia: 10 berita\n",
      "Memproses 10 berita yang berhasil dianalisis...\n",
      "‚úÖ Laporan disimpan di 00_laporan_cetak/daftar_berita_20251001_083028.txt\n",
      "üìÑ Total baris: 36\n",
      "\n",
      "üìã Preview laporan:\n",
      "------------------------------------------------------------\n",
      "Daftar Berita & Konten\n",
      "Rabu, 1 Oktober 2025\n",
      "Periode pantauan tanggal 30-1 September 2025 (pukul 14.00 s.d. 06.00 WIB)\n",
      "\n",
      "Media Online\n",
      "===========\n",
      "\n",
      "üü¢ Omongan Purbaya Sukses Bangkitkan Rupiah, Ini Buktinya! - CNBC Indonesia\n",
      "https://www.cnbcindonesia.com/news/20250929141335-4-671135/omongan-purbaya-sukses-bangkitkan-rupiah-ini-buktinya\n",
      "\n",
      "üü¢ Purbaya Umumkan Cukai Rokok 2026 Tak Naik, Airlangga: Bagus! - CNBC Indonesia\n",
      "https://www.cnbcindonesia.com/news/20250929201058-4-671319/purbaya-umumkan-cukai-rokok-2026-tak-naik-airlangga-bagus\n",
      "...\n",
      "[24 baris lainnya]\n",
      "------------------------------------------------------------\n",
      "\n",
      "üéØ Selesai! File tersedia di folder: 00_laporan_cetak/\n"
     ]
    }
   ],
   "source": [
    "# SEL 2 - Generator Laporan \"Daftar Berita & Konten\" (Fixed Version)\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "def get_sentiment_emoji(sentimen):\n",
    "    \"\"\"Convert sentimen to emoji atau tag\"\"\"\n",
    "    if not sentimen:\n",
    "        return \"üü°\"\n",
    "    sentimen_lower = str(sentimen).lower()\n",
    "    if 'pos' in sentimen_lower:\n",
    "        return \"üü¢\"\n",
    "    elif 'neg' in sentimen_lower:\n",
    "        return \"üî¥\"\n",
    "    else:\n",
    "        return \"üü°\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text dari karakter bermasalah\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Gunakan replace untuk karakter bermasalah umum\n",
    "    clean = str(text).replace('\\udcca', '').replace('\\udccb', '').replace('\\x00', '')\n",
    "    return clean.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "def format_indonesian_date():\n",
    "    \"\"\"Format tanggal hari ini dalam bahasa Indonesia\"\"\"\n",
    "    today = datetime.now()\n",
    "    days = ['Senin', 'Selasa', 'Rabu', 'Kamis', 'Jumat', 'Sabtu', 'Minggu']\n",
    "    months = ['Januari', 'Februari', 'Maret', 'April', 'Mei', 'Juni',\n",
    "              'Juli', 'Agustus', 'September', 'Oktober', 'November', 'Desember']\n",
    "    \n",
    "    day_name = days[today.weekday()]\n",
    "    day = today.day\n",
    "    month = months[today.month - 1]\n",
    "    year = today.year\n",
    "    \n",
    "    return f\"{day_name}, {day} {month} {year}\"\n",
    "\n",
    "def generate_daftar_berita_konten(df_data):\n",
    "    \"\"\"Generate laporan Daftar Berita & Konten\"\"\"\n",
    "    \n",
    "    # Header laporan\n",
    "    today = datetime.now()\n",
    "    yesterday = today - timedelta(days=1)\n",
    "    tanggal_laporan = format_indonesian_date()\n",
    "    \n",
    "    lines = []\n",
    "    lines.append(\"Daftar Berita & Konten\")\n",
    "    lines.append(tanggal_laporan)\n",
    "    lines.append(f\"Periode pantauan tanggal {yesterday.day}-{today.day} September 2025 (pukul 14.00 s.d. 06.00 WIB)\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Media Online\")\n",
    "    lines.append(\"===========\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Filter data yang berhasil dianalisis\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok'].copy()\n",
    "    \n",
    "    if success_data.empty:\n",
    "        lines.append(\"Tidak ada berita yang berhasil dianalisis.\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    print(f\"Memproses {len(success_data)} berita yang berhasil dianalisis...\")\n",
    "    \n",
    "    # Sort berdasarkan sentimen: positif dulu\n",
    "    sentimen_order = {'Positif': 1, 'Netral': 2, 'Negatif': 3}\n",
    "    if 'sentimen' in success_data.columns:\n",
    "        success_data['sentimen_score'] = success_data['sentimen'].map(sentimen_order).fillna(4)\n",
    "        success_data = success_data.sort_values('sentimen_score')\n",
    "    \n",
    "    # Generate entry untuk setiap berita\n",
    "    for idx, row in success_data.iterrows():\n",
    "        # Ambil data\n",
    "        judul_raw = row.get('judul_berita', 'Judul tidak tersedia')\n",
    "        url = row.get('url_berita', row.get('link', ''))\n",
    "        sentimen = row.get('sentimen', 'Netral')\n",
    "        \n",
    "        # Clean text\n",
    "        judul_clean = clean_text(judul_raw)\n",
    "        if len(judul_clean.strip()) < 10:  # Jika terlalu banyak karakter hilang\n",
    "            judul_clean = \"Berita Terkait Kementerian Keuangan\"\n",
    "        \n",
    "        # Format emoji sentimen\n",
    "        emoji = get_sentiment_emoji(sentimen)\n",
    "        \n",
    "        # Format entry\n",
    "        berita_line = f\"{emoji} {judul_clean}\"\n",
    "        lines.append(berita_line)\n",
    "        \n",
    "        if url and url.strip() and url != '#':\n",
    "            url_clean = clean_text(url)\n",
    "            if url_clean.strip():\n",
    "                lines.append(url_clean)\n",
    "        lines.append(\"\")  # Baris kosong pemisah\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_laporan_txt(content, filename_prefix=\"daftar_berita\"):\n",
    "    \"\"\"Simpan konten laporan ke file txt\"\"\"\n",
    "    # Buat direktori output\n",
    "    output_dir = Path(\"00_laporan_cetak\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate filename dengan timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_prefix}_{timestamp}.txt\"\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    # Tulis file dengan encoding yang aman\n",
    "    with open(filepath, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# ===== EKSEKUSI GENERATOR ===== #\n",
    "print(\"=== GENERATOR DAFTAR BERITA & KONTEN ===\")\n",
    "\n",
    "# Check data availability\n",
    "if 'analisis_berita_penting' not in globals():\n",
    "    print(\"‚ùå Data analisis_berita_penting tidak tersedia. Jalankan SEL 1 dulu.\")\n",
    "elif analisis_berita_penting.empty:\n",
    "    print(\"‚ùå DataFrame analisis_berita_penting kosong.\")\n",
    "else:\n",
    "    print(f\"üìä Data tersedia: {len(analisis_berita_penting)} berita\")\n",
    "    \n",
    "    # Generate laporan\n",
    "    try:\n",
    "        laporan_content = generate_daftar_berita_konten(analisis_berita_penting)\n",
    "        \n",
    "        # Simpan ke file\n",
    "        saved_file = save_laporan_txt(laporan_content, \"daftar_berita\")\n",
    "        \n",
    "        print(f\"‚úÖ Laporan disimpan di {saved_file}\")\n",
    "        print(f\"üìÑ Total baris: {len(laporan_content.splitlines())}\")\n",
    "        \n",
    "        # Preview (10 baris pertama)\n",
    "        preview_lines = laporan_content.splitlines()[:12]\n",
    "        print(\"\\nüìã Preview laporan:\")\n",
    "        print(\"-\" * 60)\n",
    "        for line in preview_lines:\n",
    "            if line.strip():\n",
    "                print(line)\n",
    "            else:\n",
    "                print(\"\")  # Baris kosong\n",
    "        if len(laporan_content.splitlines()) > 12:\n",
    "            print(\"...\")\n",
    "            print(f\"[{len(laporan_content.splitlines()) - 12} baris lainnya]\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {str(e)}\")\n",
    "        # Buat fallback laporan minimal\n",
    "        fallback_content = f\"\"\"Daftar Berita & Konten\n",
    "{format_indonesian_date()}\n",
    "\n",
    "Media Online\n",
    "===========\n",
    "\n",
    "Total berita: {len(analisis_berita_penting)}\n",
    "Berhasil dianalisis: {(analisis_berita_penting['analisis_status'] == 'ok').sum()}\n",
    "\n",
    "[Detail laporan tidak dapat dibuat - silakan cek file CSV]\n",
    "\"\"\"\n",
    "        \n",
    "        saved_file = save_laporan_txt(fallback_content, \"daftar_berita_fallback\")\n",
    "        print(f\"üìÑ Laporan fallback disimpan di {saved_file}\")\n",
    "\n",
    "print(\"\\nüéØ Selesai! File tersedia di folder: 00_laporan_cetak/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97842265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:33:43,098 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using DEEPSEEK for headline generation\n",
      "=== GENERATOR NEWS UPDATE ===\n",
      "üìä Data tersedia: 10 berita\n",
      "\n",
      "üìù Gabungan resume (2868 karakter):\n",
      "Preview: Rupiah menguat 0,51% ke Rp16.640/US$ setelah klarifikasi Menteri Keuangan Purbaya mengenai kebijakan deposito valas 4%. Pasar merespons positif penjelasan bahwa rencana kenaikan deposito valas dibatal...\n",
      "\n",
      "‚úÖ News Update disimpan di: 00_laporan_cetak/news_update_general_20251001_083353.txt\n",
      "üìÑ Total baris: 33\n",
      "\n",
      "üìã Preview News Update:\n",
      "------------------------------------------------------------\n",
      "News Update\n",
      "Menkeu Sidak BNI\n",
      "Jakarta, Rabu, 1 Oktober 2025 (Pukul 08.00 WIB)\n",
      "\n",
      "Pemberitaan terkait menkeu sidak bni hari ini tercatat terdapat 10 berita (10 netral) di media online.\n",
      "\n",
      "Sorotan Media Online\n",
      "‚Ä¢ Rupiah menguat 0,51% ke Rp16.640/US$ setelah pemerintah batalkan rencana kenaikan deposito valas.\n",
      "‚Ä¢ Menkeu pastikan tidak ada kenaikan cukai rokok pada 2026, fokus dialihkan ke pemberantasan rokok ilegal.\n",
      "‚Ä¢ Menkeu lakukan sidak mendadak ke kantor BNI untuk pantau kinerja dan dukung program prioritas pemerintah.\n",
      "‚Ä¢ Pemerintah siapkan tambahan anggaran program makan bergizi gratis setelah penyerapan dinilai lebih baik dari perkiraan.\n",
      "‚Ä¢ Bea Cukai Batam gagalkan penyelundupan ratusan iPhone bekas, konferensi pers rincian akan digelar Rabu.\n",
      "‚Ä¢ Penguatan Rupiah didukung oleh surplus neraca dagang dan imbal hasil yang menarik bagi investor.\n",
      "‚Ä¢ Menko Perekonomian sambut positif keputusan Menkeu untuk tidak menaikkan cukai rokok pada tahun 2026.\n",
      "‚Ä¢ Sidak Menkeu ke BNI juga untuk pastikan optimalnya alokasi dana likuiditas Rp 55 triliun.\n",
      "...\n",
      "[18 baris lainnya]\n",
      "------------------------------------------------------------\n",
      "\n",
      "üéØ Selesai! File tersedia di: 00_laporan_cetak/\n",
      "\n",
      "‚úÖ News Update disimpan di: 00_laporan_cetak/news_update_general_20251001_083353.txt\n",
      "üìÑ Total baris: 33\n",
      "\n",
      "üìã Preview News Update:\n",
      "------------------------------------------------------------\n",
      "News Update\n",
      "Menkeu Sidak BNI\n",
      "Jakarta, Rabu, 1 Oktober 2025 (Pukul 08.00 WIB)\n",
      "\n",
      "Pemberitaan terkait menkeu sidak bni hari ini tercatat terdapat 10 berita (10 netral) di media online.\n",
      "\n",
      "Sorotan Media Online\n",
      "‚Ä¢ Rupiah menguat 0,51% ke Rp16.640/US$ setelah pemerintah batalkan rencana kenaikan deposito valas.\n",
      "‚Ä¢ Menkeu pastikan tidak ada kenaikan cukai rokok pada 2026, fokus dialihkan ke pemberantasan rokok ilegal.\n",
      "‚Ä¢ Menkeu lakukan sidak mendadak ke kantor BNI untuk pantau kinerja dan dukung program prioritas pemerintah.\n",
      "‚Ä¢ Pemerintah siapkan tambahan anggaran program makan bergizi gratis setelah penyerapan dinilai lebih baik dari perkiraan.\n",
      "‚Ä¢ Bea Cukai Batam gagalkan penyelundupan ratusan iPhone bekas, konferensi pers rincian akan digelar Rabu.\n",
      "‚Ä¢ Penguatan Rupiah didukung oleh surplus neraca dagang dan imbal hasil yang menarik bagi investor.\n",
      "‚Ä¢ Menko Perekonomian sambut positif keputusan Menkeu untuk tidak menaikkan cukai rokok pada tahun 2026.\n",
      "‚Ä¢ Sidak Menkeu ke BNI juga untuk pastikan optimalnya alokasi dana likuiditas Rp 55 triliun.\n",
      "...\n",
      "[18 baris lainnya]\n",
      "------------------------------------------------------------\n",
      "\n",
      "üéØ Selesai! File tersedia di: 00_laporan_cetak/\n"
     ]
    }
   ],
   "source": [
    "# SEL 3 - Generator News Update dengan AI Analysis\n",
    "# Gabungkan ringkasan berita dari proses di sel menjadi satu paragraf panjang. \n",
    "# Buat prompt untuk membuat maksimal 10 headline untuk mengisi sorotan_media_online\n",
    "# Tambahkan Tautan media online yang sesuai headline tersebut dari database.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup AI client untuk headline generation - menggunakan konfigurasi dinamis\n",
    "_client_ai = None\n",
    "_call_ai_model = None\n",
    "\n",
    "if 'AI_CLIENT' in globals() and 'CALL_AI_MODEL' in globals():\n",
    "    _client_ai = AI_CLIENT\n",
    "    _call_ai_model = CALL_AI_MODEL\n",
    "    ai_provider = os.getenv('MODEL_ANALISIS', 'openai').upper()\n",
    "    print(f\"‚úÖ Using {ai_provider} for headline generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è AI configuration not found. Headlines will use fallback method.\")\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load config.json untuk mendapat topic keywords\"\"\"\n",
    "    try:\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Tidak dapat memuat config.json: {e}\")\n",
    "        return {}\n",
    "\n",
    "def clean_text_safe(text):\n",
    "    \"\"\"Safe text cleaning\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return str(text).encode('utf-8', 'ignore').decode('utf-8').strip()\n",
    "\n",
    "def combine_resumes(df_data):\n",
    "    \"\"\"Gabungkan semua resume berita menjadi satu paragraf panjang\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    if success_data.empty:\n",
    "        return \"Tidak ada resume berita yang tersedia.\"\n",
    "    \n",
    "    # Gabungkan semua resume\n",
    "    all_resumes = []\n",
    "    for _, row in success_data.iterrows():\n",
    "        resume = clean_text_safe(row.get('resume_ai', ''))\n",
    "        if resume and len(resume) > 10:\n",
    "            all_resumes.append(resume)\n",
    "    \n",
    "    if not all_resumes:\n",
    "        return \"Resume berita tidak tersedia.\"\n",
    "    \n",
    "    # Gabungkan dengan connector yang natural\n",
    "    combined = \". \".join(all_resumes)\n",
    "    return combined\n",
    "\n",
    "def count_sentiment_stats(df_data):\n",
    "    \"\"\"Hitung statistik sentimen\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    if success_data.empty:\n",
    "        return 0, 0, 0, 0\n",
    "    \n",
    "    total = len(success_data)\n",
    "    positif = len(success_data[success_data['sentimen'].str.contains('Positif', na=False)])\n",
    "    negatif = len(success_data[success_data['sentimen'].str.contains('Negatif', na=False)])\n",
    "    netral = total - positif - negatif\n",
    "    \n",
    "    return total, positif, negatif, netral\n",
    "\n",
    "def generate_headlines_with_ai(combined_resumes, topic_keywords, df_data):\n",
    "    \"\"\"Generate headlines menggunakan AI\"\"\"\n",
    "    try:\n",
    "        if not _call_ai_model:\n",
    "            ai_provider = os.getenv('MODEL_ANALISIS', 'unknown').upper()\n",
    "            print(f\"Warning: {ai_provider} tidak tersedia, menggunakan fallback headlines\")\n",
    "            return generate_fallback_headlines(df_data)\n",
    "        \n",
    "        # Build prompt untuk AI\n",
    "        keywords_str = \", \".join(topic_keywords) if topic_keywords else \"Kementerian Keuangan, ekonomi, fiskal\"\n",
    "        \n",
    "        prompt = f\"\"\"Berdasarkan ringkasan berita berikut, buatlah maksimal 8 poin sorotan media online yang menarik dan informatif.\n",
    "\n",
    "RINGKASAN GABUNGAN BERITA:\n",
    "{combined_resumes[:2000]}\n",
    "\n",
    "TOPIK YANG DIPANTAU: {keywords_str}\n",
    "\n",
    "TUGAS:\n",
    "1. Buat 5-8 poin sorotan yang merangkum isu-isu utama, setiap poin sorotan harus berbeda satu dengan yang lain.\n",
    "2. Fokus pada aspek Kementerian Keuangan, ekonomi, dan kebijakan fiskal\n",
    "3. Setiap poin maksimal 25 kata\n",
    "4. Gunakan bahasa Indonesia yang profesional\n",
    "5. Format: satu poin per baris, dimulai dengan \"‚Ä¢ \"\n",
    "\n",
    "CONTOH FORMAT:\n",
    "‚Ä¢ Menkeu melakukan inspeksi mendadak ke kantor pusat BNI untuk memantau penyaluran kredit perbankan.\n",
    "‚Ä¢ Kebijakan cukai tembakau 2026 tidak mengalami kenaikan untuk melindungi industri dan pekerja.\n",
    "\n",
    "Buat poin sorotan sekarang:\"\"\"\n",
    "\n",
    "        ai_response = _call_ai_model(prompt, temperature=0.3, max_tokens=600)\n",
    "        \n",
    "        # Parse response menjadi list headlines\n",
    "        headlines = []\n",
    "        for line in ai_response.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('‚Ä¢'):\n",
    "                headline = line[1:].strip()\n",
    "                if len(headline) > 10:  # Filter headline yang terlalu pendek\n",
    "                    headlines.append(headline)\n",
    "        \n",
    "        return headlines[:8]  # Maksimal 8 headlines\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating AI headlines: {e}\")\n",
    "        return generate_fallback_headlines(df_data)\n",
    "\n",
    "def generate_fallback_headlines(df_data):\n",
    "    \"\"\"Generate headlines fallback tanpa AI\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    headlines = []\n",
    "    for _, row in success_data.head(6).iterrows():\n",
    "        resume = clean_text_safe(row.get('resume_ai', ''))\n",
    "        if resume and len(resume) > 15:\n",
    "            # Potong di titik atau koma pertama untuk jadi headline\n",
    "            headline = resume.split('.')[0].split(',')[0]\n",
    "            if len(headline) > 20 and len(headline) < 100:\n",
    "                headlines.append(headline.strip())\n",
    "    \n",
    "    return headlines\n",
    "\n",
    "def get_main_topic_from_data(df_data, config):\n",
    "    \"\"\"Tentukan topik utama berdasarkan data berita\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    if success_data.empty:\n",
    "        return \"Monitoring Berita Kementerian Keuangan\"\n",
    "    \n",
    "    # Ambil kata kunci dari judul-judul berita\n",
    "    all_titles = \" \".join([clean_text_safe(row.get('judul_berita', '')) for _, row in success_data.iterrows()])\n",
    "    \n",
    "    # Cari keyword yang sering muncul\n",
    "    common_words = ['Menkeu', 'Purbaya', 'BNI', 'Sidak', 'Cukai', 'Bank', 'Kredit', 'Ekonomi']\n",
    "    word_counts = {word: all_titles.upper().count(word.upper()) for word in common_words}\n",
    "    \n",
    "    # Ambil kata dengan frekuensi tertinggi\n",
    "    most_common = max(word_counts.items(), key=lambda x: x[1])\n",
    "    if most_common[1] > 0:\n",
    "        if 'SIDAK' in all_titles.upper() and 'BNI' in all_titles.upper():\n",
    "            return \"Menkeu Sidak BNI\"\n",
    "        elif 'CUKAI' in all_titles.upper():\n",
    "            return \"Kebijakan Cukai Tembakau\"\n",
    "        elif 'MENKEU' in all_titles.upper() or 'PURBAYA' in all_titles.upper():\n",
    "            return \"Aktivitas Menteri Keuangan\"\n",
    "    \n",
    "    return \"Monitoring Berita Kementerian Keuangan\"\n",
    "\n",
    "def get_related_links(df_data, max_links=8):\n",
    "    \"\"\"Ambil link berita yang relevan untuk tautan media online\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    if success_data.empty:\n",
    "        return []\n",
    "    \n",
    "    links = []\n",
    "    for idx, row in success_data.head(max_links).iterrows():\n",
    "        judul = clean_text_safe(row.get('judul_berita', ''))\n",
    "        url = clean_text_safe(row.get('url_berita', row.get('link', '')))\n",
    "        \n",
    "        if judul and url and url != '#':\n",
    "            # Potong judul jika terlalu panjang\n",
    "            if len(judul) > 80:\n",
    "                judul = judul[:80] + \"...\"\n",
    "            \n",
    "            links.append({\n",
    "                'judul': judul,\n",
    "                'url': url\n",
    "            })\n",
    "    \n",
    "    return links\n",
    "\n",
    "def generate_news_update(df_data, config=None):\n",
    "    \"\"\"Generate News Update format lengkap\"\"\"\n",
    "    \n",
    "    if config is None:\n",
    "        config = {}\n",
    "    \n",
    "    # Ambil data statistik\n",
    "    total, positif, negatif, netral = count_sentiment_stats(df_data)\n",
    "    \n",
    "    if total == 0:\n",
    "        return \"News Update tidak dapat dibuat: tidak ada berita yang berhasil dianalisis.\"\n",
    "    \n",
    "    # Header informasi\n",
    "    today = datetime.now()\n",
    "    hari_indo = ['Senin', 'Selasa', 'Rabu', 'Kamis', 'Jumat', 'Sabtu', 'Minggu'][today.weekday()]\n",
    "    tanggal_indo = f\"{today.day} Oktober {today.year}\"\n",
    "    waktu_laporan = f\"{hari_indo}, {tanggal_indo} (Pukul {today.hour:02d}.00 WIB)\"\n",
    "    \n",
    "    # Tentukan topik utama\n",
    "    main_topic = get_main_topic_from_data(df_data, config)\n",
    "    \n",
    "    # Gabungkan resume\n",
    "    combined_resumes = combine_resumes(df_data)\n",
    "    \n",
    "    # Generate headlines dengan AI\n",
    "    topic_keywords = config.get('topic_keywords', [])\n",
    "    headlines = generate_headlines_with_ai(combined_resumes, topic_keywords, df_data)\n",
    "    \n",
    "    # Ambil tautan terkait\n",
    "    related_links = get_related_links(df_data)\n",
    "    \n",
    "    # Build content\n",
    "    lines = []\n",
    "    lines.append(\"News Update\")\n",
    "    lines.append(main_topic)\n",
    "    lines.append(f\"Jakarta, {waktu_laporan}\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Statistik berita\n",
    "    stats_text = f\"Pemberitaan terkait {main_topic.lower()} hari ini tercatat terdapat {total} berita\"\n",
    "    if positif > 0 or negatif > 0 or netral > 0:\n",
    "        detail_stats = []\n",
    "        if positif > 0:\n",
    "            detail_stats.append(f\"{positif} positif\")\n",
    "        if netral > 0:\n",
    "            detail_stats.append(f\"{netral} netral\")\n",
    "        if negatif > 0:\n",
    "            detail_stats.append(f\"{negatif} negatif\")\n",
    "        \n",
    "        if detail_stats:\n",
    "            stats_text += f\" ({', '.join(detail_stats)})\"\n",
    "    \n",
    "    stats_text += \" di media online.\"\n",
    "    lines.append(stats_text)\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Sorotan Media Online\n",
    "    lines.append(\"Sorotan Media Online\")\n",
    "    if headlines:\n",
    "        for headline in headlines:\n",
    "            lines.append(f\"‚Ä¢ {headline}\")\n",
    "    else:\n",
    "        lines.append(\"‚Ä¢ Tidak ada sorotan khusus tersedia.\")\n",
    "    \n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Tautan Media Online\n",
    "    lines.append(\"Tautan Media Online:\")\n",
    "    if related_links:\n",
    "        for i, link in enumerate(related_links, 1):\n",
    "            lines.append(f\" {i}. {link['judul']}\")\n",
    "            lines.append(f\"    {link['url']}\")\n",
    "    else:\n",
    "        lines.append(\" 1. Tidak ada tautan tersedia\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_news_update(content, filename_prefix=\"news_update\"):\n",
    "    \"\"\"Simpan News Update ke file txt\"\"\"\n",
    "    output_dir = Path(\"00_laporan_cetak\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_prefix}_{timestamp}.txt\"\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# ===== EKSEKUSI SEL 3 ===== #\n",
    "print(\"=== GENERATOR NEWS UPDATE ===\")\n",
    "\n",
    "# Check data\n",
    "if 'analisis_berita_penting' not in globals() or analisis_berita_penting.empty:\n",
    "    print(\"‚ùå Data analisis_berita_penting tidak tersedia. Jalankan SEL 1 terlebih dahulu.\")\n",
    "else:\n",
    "    print(f\"üìä Data tersedia: {len(analisis_berita_penting)} berita\")\n",
    "    \n",
    "    # Load config\n",
    "    config = load_config()\n",
    "    \n",
    "    # Preview gabungan resume\n",
    "    combined_resumes = combine_resumes(analisis_berita_penting)\n",
    "    print(f\"\\nüìù Gabungan resume ({len(combined_resumes)} karakter):\")\n",
    "    print(f\"Preview: {combined_resumes[:200]}...\")\n",
    "    \n",
    "    # Generate news update\n",
    "    try:\n",
    "        news_update_content = generate_news_update(analisis_berita_penting, config)\n",
    "        \n",
    "        # Simpan file\n",
    "        saved_file = save_news_update(news_update_content, \"news_update_general\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ News Update disimpan di: {saved_file}\")\n",
    "        print(f\"üìÑ Total baris: {len(news_update_content.splitlines())}\")\n",
    "        \n",
    "        # Preview hasil\n",
    "        preview_lines = news_update_content.splitlines()[:15]\n",
    "        print(f\"\\nüìã Preview News Update:\")\n",
    "        print(\"-\" * 60)\n",
    "        for line in preview_lines:\n",
    "            print(line)\n",
    "        if len(news_update_content.splitlines()) > 15:\n",
    "            print(\"...\")\n",
    "            print(f\"[{len(news_update_content.splitlines()) - 15} baris lainnya]\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating news update: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüéØ Selesai! File tersedia di: 00_laporan_cetak/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e026da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using DEEPSEEK for topic analysis\n",
      "=== GENERATOR LAPORAN ANALISIS MEDIA (FIXED VERSION) ===\n",
      "üìä Data tersedia: 10 berita\n",
      "üìã Topic keywords dari config: ['rokok ilegal', 'makan bergizi gratis', 'tax amnesty', 'sidak BNI']\n",
      "üè∑Ô∏è  Berita dikelompokkan dalam 2 topik:\n",
      "   - rokok ilegal: 2 berita\n",
      "   - makan bergizi gratis: 1 berita\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 08:38:02,777 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:38:10,271 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 08:38:10,271 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Laporan Analisis Media disimpan di: 00_laporan_cetak/laporan_analisis_media_20251001_083816.txt\n",
      "üìÑ Total baris: 46\n",
      "\n",
      "üìã Preview Laporan Analisis Media:\n",
      "----------------------------------------------------------------------\n",
      "===== Page 1 =====\n",
      "\n",
      "**Laporan Analisis Media Online dan Media Sosial**\n",
      "Rabu, 1 Oktober 2025\n",
      "\n",
      "**EXECUTIVE SUMMARY**\n",
      "==================================================\n",
      "Periode pemantauan media online menunjukkan 10 berita penting yang berhasil dianalisis.\n",
      "Dari jumlah tersebut, 3 berita sesuai dengan topik yang dipantau: rokok ilegal, makan bergizi gratis.\n",
      "Fokus pemerintah terutama pada transparansi dan pengawasan sektor keuangan.\n",
      "Pernyataan dan kebijakan penting dari pejabat terkait terus dipantau secara intensif.\n",
      "\n",
      "**MEDIA ONLINE**\n",
      "\n",
      "**Topik Berita:** rokok ilegal, makan bergizi gratis\n",
      "**Tonasi Berita:** positif\n",
      "\n",
      "**Pesan Kunci dan Analisis:**\n",
      "\n",
      "**ISU KEMENKEU**\n",
      "...\n",
      "[26 baris lainnya]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üéØ Selesai! File tersedia di: 00_laporan_cetak/\n"
     ]
    }
   ],
   "source": [
    "# SEL 4 - Generator Laporan Analisis Media Online dan Media Sosial (Fixed Version)\n",
    "# Format Laporan Analisis Berita\n",
    "# Lengkapi sel ini dengan cara untuk memanggil open AI dengan feeding data berupa:\n",
    "# 1. Gabungan dari resume berita yang ada dikelompokkan dalam topik terpisah sesuai config.json 'topic_keywords'\n",
    "# 2. Topik Berita di dokumen diambil dari config.json 'topic_keywords', masing-masing topic harus ada resume berita singkat. \n",
    "# 3. Masing-masing topic harus diberikan poin 2-3 poin penjelasan.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Setup AI client - menggunakan konfigurasi dinamis\n",
    "_client_ai = None\n",
    "_call_ai_model = None\n",
    "\n",
    "if 'AI_CLIENT' in globals() and 'CALL_AI_MODEL' in globals():\n",
    "    _client_ai = AI_CLIENT\n",
    "    _call_ai_model = CALL_AI_MODEL\n",
    "    ai_provider = os.getenv('MODEL_ANALISIS', 'openai').upper()\n",
    "    print(f\"‚úÖ Using {ai_provider} for topic analysis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è AI configuration not found. Analysis will use fallback method.\")\n",
    "\n",
    "def load_config_keywords():\n",
    "    \"\"\"Load config.json untuk mendapat topic keywords\"\"\"\n",
    "    try:\n",
    "        with open('config.json', 'r', encoding='utf-8') as f:\n",
    "            config = json.load(f)\n",
    "        return config.get('topic_keywords', []), config\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Tidak dapat memuat config.json: {e}\")\n",
    "        return [], {}\n",
    "\n",
    "def clean_text_safe(text):\n",
    "    \"\"\"Safe text cleaning\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return str(text).encode('utf-8', 'ignore').decode('utf-8').strip()\n",
    "\n",
    "def format_indonesian_datetime():\n",
    "    \"\"\"Format tanggal dan waktu dalam bahasa Indonesia\"\"\"\n",
    "    today = datetime.now()\n",
    "    days = ['Senin', 'Selasa', 'Rabu', 'Kamis', 'Jumat', 'Sabtu', 'Minggu']\n",
    "    months = ['Januari', 'Februari', 'Maret', 'April', 'Mei', 'Juni',\n",
    "              'Juli', 'Agustus', 'September', 'Oktober', 'November', 'Desember']\n",
    "    \n",
    "    day_name = days[today.weekday()]\n",
    "    day = today.day\n",
    "    month = months[today.month - 1]\n",
    "    year = today.year\n",
    "    \n",
    "    return f\"{day_name}, {day} {month} {year}\"\n",
    "\n",
    "def group_news_by_topics(df_data, topic_keywords):\n",
    "    \"\"\"Kelompokkan berita berdasarkan topic keywords dari config.json - FIXED VERSION\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok'].copy()\n",
    "    \n",
    "    if success_data.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Kelompokkan berita berdasarkan topik\n",
    "    topic_groups = defaultdict(list)\n",
    "    \n",
    "    # Jika tidak ada topic_keywords, gunakan topik_llm yang ada\n",
    "    if not topic_keywords:\n",
    "        for _, row in success_data.iterrows():\n",
    "            topik = clean_text_safe(row.get('topik_llm', 'Lainnya'))\n",
    "            if topik != 'Lainnya':\n",
    "                topic_groups[topik].append(row)\n",
    "    else:\n",
    "        # Gunakan topic_keywords dari config - HANYA yang cocok dengan keywords\n",
    "        for _, row in success_data.iterrows():\n",
    "            judul = clean_text_safe(row.get('judul_berita', '')).upper()\n",
    "            resume = clean_text_safe(row.get('resume_ai', '')).upper()\n",
    "            \n",
    "            # Cek apakah berita cocok dengan keywords\n",
    "            for topic in topic_keywords:\n",
    "                topic_upper = topic.upper()\n",
    "                if topic_upper in judul or topic_upper in resume:\n",
    "                    topic_groups[topic].append(row)\n",
    "                    break  # Berita hanya masuk ke satu topik\n",
    "        \n",
    "        # TIDAK membuat kategori \"Isu Lainnya\" otomatis\n",
    "        # Hanya topik yang ada beritanya yang akan ditampilkan\n",
    "    \n",
    "    return dict(topic_groups)\n",
    "\n",
    "def analyze_sentiment_by_topic(topic_groups):\n",
    "    \"\"\"Analisis sentimen per topik\"\"\"\n",
    "    topic_sentiments = {}\n",
    "    \n",
    "    for topic, news_list in topic_groups.items():\n",
    "        sentiments = []\n",
    "        for news in news_list:\n",
    "            sentiment = clean_text_safe(news.get('sentimen', 'Netral'))\n",
    "            sentiments.append(sentiment)\n",
    "        \n",
    "        # Hitung distribusi sentimen\n",
    "        sentiment_counts = Counter(sentiments)\n",
    "        total = len(sentiments)\n",
    "        \n",
    "        # Tentukan sentimen dominan\n",
    "        if sentiment_counts.get('Positif', 0) > total * 0.5:\n",
    "            dominant = 'Positif'\n",
    "        elif sentiment_counts.get('Negatif', 0) > total * 0.3:\n",
    "            dominant = 'Negatif'\n",
    "        else:\n",
    "            dominant = 'Netral'\n",
    "        \n",
    "        topic_sentiments[topic] = {\n",
    "            'dominant': dominant,\n",
    "            'distribution': dict(sentiment_counts),\n",
    "            'total': total\n",
    "        }\n",
    "    \n",
    "    return topic_sentiments\n",
    "\n",
    "def generate_topic_analysis_with_ai(topic, news_list, topic_keywords):\n",
    "    \"\"\"Generate analisis untuk satu topik menggunakan AI\"\"\"\n",
    "    \n",
    "    if not _call_ai_model:\n",
    "        return generate_fallback_topic_analysis(topic, news_list)\n",
    "    \n",
    "    # Gabungkan semua resume untuk topik ini\n",
    "    resumes = []\n",
    "    for news in news_list[:5]:  # Maksimal 5 berita per topik\n",
    "        resume = clean_text_safe(news.get('resume_ai', ''))\n",
    "        if resume:\n",
    "            resumes.append(resume)\n",
    "    \n",
    "    combined_resumes = \". \".join(resumes)\n",
    "    \n",
    "    # Build prompt untuk AI\n",
    "    prompt = f\"\"\"Analisis topik berita berikut dan buat analisis profesional:\n",
    "\n",
    "TOPIK: {topic}\n",
    "RINGKASAN BERITA: {combined_resumes[:1500]}\n",
    "\n",
    "Tugas:\n",
    "1. Buat ringkasan singkat topik ini (maksimal 40 kata)\n",
    "2. Buat 2-3 poin analisis utama (masing-masing maksimal 25 kata)\n",
    "3. Fokus pada dampak untuk Kementerian Keuangan atau kebijakan ekonomi\n",
    "\n",
    "Format output:\n",
    "RINGKASAN: [ringkasan singkat]\n",
    "POIN 1: [analisis poin 1]\n",
    "POIN 2: [analisis poin 2]\n",
    "POIN 3: [analisis poin 3 jika ada]\n",
    "\n",
    "Contoh:\n",
    "RINGKASAN: Menteri Keuangan melakukan inspeksi ke BNI untuk memantau kinerja\n",
    "POIN 1: Transparansi sektor perbankan menjadi fokus utama\n",
    "POIN 2: Pengawasan kredit perbankan diperkuat\"\"\"\n",
    "\n",
    "    try:\n",
    "        ai_response = _call_ai_model(prompt, temperature=0.3, max_tokens=500)\n",
    "        \n",
    "        # Parse response\n",
    "        lines = ai_response.strip().split('\\n')\n",
    "        result = {\n",
    "            'ringkasan': '',\n",
    "            'poin_analisis': []\n",
    "        }\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('RINGKASAN:'):\n",
    "                result['ringkasan'] = line.replace('RINGKASAN:', '').strip()\n",
    "            elif line.startswith('POIN'):\n",
    "                poin_text = re.sub(r'^POIN \\d+:', '', line).strip()\n",
    "                if poin_text:\n",
    "                    result['poin_analisis'].append(poin_text)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating AI analysis for topic {topic}: {e}\")\n",
    "        return generate_fallback_topic_analysis(topic, news_list)\n",
    "\n",
    "def generate_fallback_topic_analysis(topic, news_list):\n",
    "    \"\"\"Generate analisis fallback tanpa AI\"\"\"\n",
    "    # Ambil resume pertama sebagai ringkasan\n",
    "    ringkasan = \"Tidak ada analisis tersedia.\"\n",
    "    if news_list:\n",
    "        first_resume = clean_text_safe(news_list[0].get('resume_ai', ''))\n",
    "        if first_resume:\n",
    "            ringkasan = first_resume[:100] + \"...\" if len(first_resume) > 100 else first_resume\n",
    "    \n",
    "    poin_analisis = [\n",
    "        f\"Terdapat {len(news_list)} berita terkait topik {topic}\",\n",
    "        \"Memerlukan pemantauan lebih lanjut dari perspektif kebijakan fiskal\"\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        'ringkasan': ringkasan,\n",
    "        'poin_analisis': poin_analisis\n",
    "    }\n",
    "\n",
    "def categorize_topics(topic_groups, topic_keywords):\n",
    "    \"\"\"Kategorikan topik menjadi ISU KEMENKEU vs ISU NASIONAL/INTERNASIONAL\"\"\"\n",
    "    kemenkeu_keywords = [\n",
    "        'Menkeu', 'Kementerian Keuangan', 'Pajak', 'Cukai', 'APBN', 'Fiskal', \n",
    "        'Bea Cukai', 'DJP', 'Purbaya', 'Sidak', 'Bank', 'Kredit', 'Ekonomi'\n",
    "    ]\n",
    "    \n",
    "    isu_kemenkeu = {}\n",
    "    isu_nasional = {}\n",
    "    \n",
    "    for topic, news_list in topic_groups.items():\n",
    "        # Cek apakah topik terkait Kemenkeu\n",
    "        is_kemenkeu = False\n",
    "        topic_upper = topic.upper()\n",
    "        \n",
    "        for keyword in kemenkeu_keywords:\n",
    "            if keyword.upper() in topic_upper:\n",
    "                is_kemenkeu = True\n",
    "                break\n",
    "        \n",
    "        # Jika tidak jelas dari nama topik, cek dari isi berita\n",
    "        if not is_kemenkeu and news_list:\n",
    "            sample_text = \" \".join([\n",
    "                clean_text_safe(news.get('judul_berita', '')).upper() + \" \" +\n",
    "                clean_text_safe(news.get('resume_ai', '')).upper()\n",
    "                for news in news_list[:3]\n",
    "            ])\n",
    "            \n",
    "            for keyword in kemenkeu_keywords:\n",
    "                if keyword.upper() in sample_text:\n",
    "                    is_kemenkeu = True\n",
    "                    break\n",
    "        \n",
    "        if is_kemenkeu:\n",
    "            isu_kemenkeu[topic] = news_list\n",
    "        else:\n",
    "            isu_nasional[topic] = news_list\n",
    "    \n",
    "    return isu_kemenkeu, isu_nasional\n",
    "\n",
    "def extract_narasumber(df_data):\n",
    "    \"\"\"Extract narasumber utama dari berita\"\"\"\n",
    "    success_data = df_data[df_data['analisis_status'] == 'ok']\n",
    "    \n",
    "    # Cari nama-nama yang sering muncul (kemungkinan narasumber)\n",
    "    all_text = \"\"\n",
    "    \n",
    "    for _, row in success_data.iterrows():\n",
    "        judul = clean_text_safe(row.get('judul_berita', ''))\n",
    "        resume = clean_text_safe(row.get('resume_ai', ''))\n",
    "        all_text += f\" {judul} {resume}\"\n",
    "    \n",
    "    # Cari nama-nama pejabat yang umum\n",
    "    known_officials = [\n",
    "        'Purbaya Yudhi Sadewa', 'Menkeu Purbaya', 'Menteri Keuangan',\n",
    "        'Dirjen Pajak', 'Dirjen Bea Cukai', 'Kepala Bappenas',\n",
    "        'Gubernur BI', 'Direktur BNI', 'Presiden Jokowi'\n",
    "    ]\n",
    "    \n",
    "    found_narasumber = []\n",
    "    for official in known_officials:\n",
    "        if official.upper() in all_text.upper():\n",
    "            found_narasumber.append(official)\n",
    "    \n",
    "    return found_narasumber[:3] if found_narasumber else [\"Belum ada narasumber\"]\n",
    "\n",
    "def generate_laporan_analisis_media(df_data, config):\n",
    "    \"\"\"Generate laporan analisis media lengkap\"\"\"\n",
    "    \n",
    "    # Load topic keywords\n",
    "    topic_keywords, _ = load_config_keywords()\n",
    "    \n",
    "    # Kelompokkan berita berdasarkan topik - HANYA yang cocok dengan keywords\n",
    "    topic_groups = group_news_by_topics(df_data, topic_keywords)\n",
    "    \n",
    "    # Jika tidak ada yang cocok dengan keywords, buat pesan informasi\n",
    "    if not topic_groups:\n",
    "        return f\"\"\"**Laporan Analisis Media Online dan Media Sosial**\n",
    "{format_indonesian_datetime()}\n",
    "\n",
    "**EXECUTIVE SUMMARY**\n",
    "==================================================\n",
    "Periode pemantauan ini tidak menemukan berita yang sesuai dengan topic keywords yang telah ditentukan dalam config.json.\n",
    "Mungkin perlu review atau penyesuaian keywords untuk menangkap lebih banyak berita yang relevan.\n",
    "\n",
    "**MEDIA ONLINE**\n",
    "**Topik Berita:** Tidak ada topik yang cocok dengan keywords\n",
    "**Tonasi Berita:** -\n",
    "\n",
    "**Kegiatan yang dirujuk:** Pemantauan Berkelanjutan\n",
    "**Narasumber utama yang dirujuk:** Belum ada narasumber\n",
    "\n",
    "Silakan periksa kembali topic_keywords di config.json atau data berita yang tersedia.\"\"\"\n",
    "    \n",
    "    # Analisis sentimen per topik\n",
    "    topic_sentiments = analyze_sentiment_by_topic(topic_groups)\n",
    "    \n",
    "    # Kategorikan topik\n",
    "    isu_kemenkeu, isu_nasional = categorize_topics(topic_groups, topic_keywords)\n",
    "    \n",
    "    # Extract narasumber\n",
    "    narasumber_list = extract_narasumber(df_data)\n",
    "    \n",
    "    # Build laporan\n",
    "    lines = []\n",
    "    \n",
    "    # ===== HEADER ===== #\n",
    "    lines.append(\"===== Page 1 =====\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"**Laporan Analisis Media Online dan Media Sosial**\")\n",
    "    lines.append(format_indonesian_datetime())\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # ===== EXECUTIVE SUMMARY ===== #\n",
    "    lines.append(\"**EXECUTIVE SUMMARY**\")\n",
    "    lines.append(\"=\" * 50)\n",
    "    \n",
    "    # Generate executive summary dengan AI jika tersedia\n",
    "    total_berita = len(df_data[df_data['analisis_status'] == 'ok'])\n",
    "    total_relevan = sum(len(news_list) for news_list in topic_groups.values())\n",
    "    main_topics = list(topic_groups.keys())[:3]\n",
    "    \n",
    "    lines.append(f\"Periode pemantauan media online menunjukkan {total_berita} berita penting yang berhasil dianalisis.\")\n",
    "    lines.append(f\"Dari jumlah tersebut, {total_relevan} berita sesuai dengan topik yang dipantau: {', '.join(main_topics)}.\")\n",
    "    \n",
    "    if isu_kemenkeu:\n",
    "        lines.append(\"Fokus pemerintah terutama pada transparansi dan pengawasan sektor keuangan.\")\n",
    "    \n",
    "    lines.append(\"Pernyataan dan kebijakan penting dari pejabat terkait terus dipantau secara intensif.\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # ===== MEDIA ONLINE ===== #\n",
    "    lines.append(\"**MEDIA ONLINE**\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # Topik Berita\n",
    "    lines.append(f\"**Topik Berita:** {', '.join(topic_groups.keys())}\")\n",
    "    \n",
    "    # Tonasi Berita Overall - FIXED VERSION\n",
    "    all_sentiments = []\n",
    "    for sentiment_data in topic_sentiments.values():\n",
    "        for sentiment, count in sentiment_data['distribution'].items():\n",
    "            # Extend dengan string sentimen sebanyak count-nya\n",
    "            all_sentiments.extend([sentiment] * count)\n",
    "            \n",
    "    sentiment_counter = Counter(all_sentiments) if all_sentiments else Counter(['Netral'])\n",
    "    dominant_sentiment = sentiment_counter.most_common(1)[0][0] if sentiment_counter else 'Netral'\n",
    "    lines.append(f\"**Tonasi Berita:** {dominant_sentiment}\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # ===== PESAN KUNCI DAN ANALISIS ===== #\n",
    "    lines.append(\"**Pesan Kunci dan Analisis:**\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # ISU KEMENKEU\n",
    "    if isu_kemenkeu:\n",
    "        lines.append(\"**ISU KEMENKEU**\")\n",
    "        for i, (topic, news_list) in enumerate(isu_kemenkeu.items(), 1):\n",
    "            # Generate AI analysis untuk topik ini\n",
    "            analysis = generate_topic_analysis_with_ai(topic, news_list, topic_keywords)\n",
    "            \n",
    "            lines.append(f\"{i}. **{topic}**\")\n",
    "            lines.append(f\"   Ringkasan: {analysis['ringkasan']}\")\n",
    "            for j, poin in enumerate(analysis['poin_analisis'], 1):\n",
    "                lines.append(f\"   - {poin}\")\n",
    "            lines.append(\"\")\n",
    "    \n",
    "    # ISU NASIONAL DAN INTERNASIONAL\n",
    "    if isu_nasional:\n",
    "        lines.append(\"**ISU NASIONAL DAN INTERNASIONAL**\")\n",
    "        for i, (topic, news_list) in enumerate(isu_nasional.items(), 1):\n",
    "            # Generate AI analysis untuk topik ini\n",
    "            analysis = generate_topic_analysis_with_ai(topic, news_list, topic_keywords)\n",
    "            \n",
    "            lines.append(f\"{i}. **{topic}**\")\n",
    "            lines.append(f\"   Ringkasan: {analysis['ringkasan']}\")\n",
    "            for j, poin in enumerate(analysis['poin_analisis'], 1):\n",
    "                lines.append(f\"   - {poin}\")\n",
    "            lines.append(\"\")\n",
    "    \n",
    "    # Jika tidak ada isu kemenkeu atau nasional, beri informasi\n",
    "    if not isu_kemenkeu and not isu_nasional:\n",
    "        lines.append(\"**ISU KEMENKEU**\")\n",
    "        lines.append(\"Tidak ada berita yang cocok dengan kategori isu Kemenkeu pada periode ini.\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"**ISU NASIONAL DAN INTERNASIONAL**\")\n",
    "        lines.append(\"Tidak ada berita yang cocok dengan kategori isu nasional/internasional pada periode ini.\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    # ===== KEGIATAN & NARASUMBER ===== #\n",
    "    lines.append(\"**Kegiatan yang dirujuk:** Kegiatan Baru, Pemantauan Berkelanjutan\")\n",
    "    lines.append(f\"**Narasumber utama yang dirujuk:** {', '.join(narasumber_list)}\")\n",
    "    lines.append(\"\")\n",
    "    \n",
    "    # ===== DAFTAR BERITA ===== #\n",
    "    lines.append(\"===== Page 2 =====\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"**Daftar Berita:**\")\n",
    "    \n",
    "    # Hanya tampilkan berita yang masuk dalam topic groups\n",
    "    displayed_count = 0\n",
    "    for topic, news_list in topic_groups.items():\n",
    "        for news in news_list:\n",
    "            displayed_count += 1\n",
    "            judul = clean_text_safe(news.get('judul_berita', 'Judul tidak tersedia'))\n",
    "            url = clean_text_safe(news.get('url_berita', news.get('link', '#')))\n",
    "            \n",
    "            lines.append(f\"{displayed_count}. {judul}\")\n",
    "            if url and url != '#':\n",
    "                lines.append(f\"[{url}]\")\n",
    "            lines.append(\"\")\n",
    "    \n",
    "    if displayed_count == 0:\n",
    "        lines.append(\"Tidak ada berita yang sesuai dengan topic keywords untuk ditampilkan.\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_laporan_analisis(content, filename_prefix=\"laporan_analisis_media\"):\n",
    "    \"\"\"Simpan laporan analisis ke file txt\"\"\"\n",
    "    output_dir = Path(\"00_laporan_cetak\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{filename_prefix}_{timestamp}.txt\"\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# ===== EKSEKUSI SEL 4 ===== #\n",
    "print(\"=== GENERATOR LAPORAN ANALISIS MEDIA (FIXED VERSION) ===\")\n",
    "\n",
    "# Check data\n",
    "if 'analisis_berita_penting' not in globals() or analisis_berita_penting.empty:\n",
    "    print(\"‚ùå Data analisis_berita_penting tidak tersedia. Jalankan SEL 1 terlebih dahulu.\")\n",
    "else:\n",
    "    print(f\"üìä Data tersedia: {len(analisis_berita_penting)} berita\")\n",
    "    \n",
    "    # Load config dan analisis topik\n",
    "    topic_keywords, config = load_config_keywords()\n",
    "    print(f\"üìã Topic keywords dari config: {topic_keywords}\")\n",
    "    \n",
    "    # Preview pengelompokan topik\n",
    "    topic_groups = group_news_by_topics(analisis_berita_penting, topic_keywords)\n",
    "\n",
    "    if topic_groups:\n",
    "        print(f\"üè∑Ô∏è  Berita dikelompokkan dalam {len(topic_groups)} topik:\")\n",
    "        for topic, news_list in topic_groups.items():\n",
    "            print(f\"   - {topic}: {len(news_list)} berita\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Tidak ada berita yang cocok dengan topic keywords dari config.json\")\n",
    "        print(\"   Laporan akan dibuat dengan informasi bahwa tidak ada topik yang cocok\")\n",
    "    \n",
    "    # Generate laporan lengkap\n",
    "    try:\n",
    "        laporan_content = generate_laporan_analisis_media(analisis_berita_penting, config)\n",
    "        \n",
    "        # Simpan file\n",
    "        saved_file = save_laporan_analisis(laporan_content, \"laporan_analisis_media\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Laporan Analisis Media disimpan di: {saved_file}\")\n",
    "        print(f\"üìÑ Total baris: {len(laporan_content.splitlines())}\")\n",
    "        \n",
    "        # Preview hasil (20 baris pertama)\n",
    "        preview_lines = laporan_content.splitlines()[:20]\n",
    "        print(f\"\\nüìã Preview Laporan Analisis Media:\")\n",
    "        print(\"-\" * 70)\n",
    "        for line in preview_lines:\n",
    "            print(line)\n",
    "        if len(laporan_content.splitlines()) > 20:\n",
    "            print(\"...\")\n",
    "            print(f\"[{len(laporan_content.splitlines()) - 20} baris lainnya]\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating laporan analisis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüéØ Selesai! File tersedia di: 00_laporan_cetak/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path /Users/yusufpradana/Library/CloudStorage/OneDrive-Personal/Pekerjaan BMN/05. 2025/98_monitoring_berita/monitoring-berita/00_laporan_cetak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
