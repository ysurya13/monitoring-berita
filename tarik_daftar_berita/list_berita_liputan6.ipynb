{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1758161399237,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "-p3dCum8mxl2",
    "outputId": "b1f764dd-db09-4ccd-e3c8-443b642b40c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# mount the colab with google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# mount the colab with google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1758161399237,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "-7PzJSNbnBYV"
   },
   "outputs": [],
   "source": [
    "# set folder tempat kerja (current working directory)\n",
    "import os\n",
    "cwd = '/Users/yusufpradana/Library/CloudStorage/OneDrive-Personal/Pekerjaan BMN/05. 2025/98_monitoring_berita/monitoring-berita'\n",
    "# cwd = '/content/drive/MyDrive/Monitoring Berita'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1758161399238,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "wJQp8NpjAL-L"
   },
   "outputs": [],
   "source": [
    "# Sel 1: Import & konfigurasi logging\n",
    "\n",
    "# %%\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from requests.exceptions import RequestException, HTTPError, Timeout\n",
    "\n",
    "# Logging konfigurasi\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(\"Liputan6Scraper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UkRIArpJjNFH"
   },
   "outputs": [],
   "source": [
    "# --- Sel 2: Parameter (mudah diubah) ---\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Kata kunci topik untuk analisis relevansi judul\n",
    "topic_keywords = config[\"keywords\"]\n",
    "\n",
    "# Daftar tanggal (YYYY-MM-DD). Akan di-convert ke DD-MM-YYYY untuk pencocokan di halaman.\n",
    "dates = config[\"search_date\"]\n",
    "\n",
    "# Maksimum halaman per tanggal (akan berhenti lebih awal jika halaman kosong)\n",
    "max_pages_per_date = config[\"max_page_length\"]\n",
    "\n",
    "# Sertakan kanal Bisnis (tanggalan) selain News\n",
    "include_bisnis = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1758161399257,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "WFQhcH6GAOcR"
   },
   "outputs": [],
   "source": [
    "# Sel 3: Kelas Liputan6Scraper\n",
    "\n",
    "# %%\n",
    "class Liputan6Scraper:\n",
    "    BASE = \"https://www.liputan6.com\"\n",
    "    NEWS_INDEX_BASE = \"https://www.liputan6.com/news/indeks\"\n",
    "    BISNIS_INDEX_BASE = \"https://www.liputan6.com/bisnis/indeks\"\n",
    "\n",
    "    def __init__(self, timeout: int = 10, max_retries: int = 3, sleep_between_pages: float = 1.0):\n",
    "        self.timeout = timeout\n",
    "        self.max_retries = max_retries\n",
    "        self.sleep_between_pages = sleep_between_pages\n",
    "\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "            ),\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"id,en;q=0.9\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        })\n",
    "\n",
    "    # ---------- HTTP GET dengan retry & exponential backoff ----------\n",
    "    def _get(self, url: str) -> requests.Response | None:\n",
    "        delay = 1.0\n",
    "        last_exc = None\n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            try:\n",
    "                resp = self.session.get(url, timeout=self.timeout)\n",
    "                if 500 <= resp.status_code < 600:\n",
    "                    raise HTTPError(f\"Server error {resp.status_code} untuk {url}\")\n",
    "                if resp.status_code == 429:\n",
    "                    raise HTTPError(\"429 Too Many Requests\")\n",
    "                if 400 <= resp.status_code < 500:\n",
    "                    logger.error(f\"HTTP {resp.status_code} pada {url}\")\n",
    "                    return None\n",
    "                return resp\n",
    "            except (Timeout, HTTPError) as e:\n",
    "                last_exc = e\n",
    "                if attempt < self.max_retries:\n",
    "                    logger.warning(f\"Percobaan {attempt}/{self.max_retries} gagal: {e} | retry dalam {int(delay)}s | {url}\")\n",
    "                    time.sleep(delay)\n",
    "                    delay *= 2\n",
    "                else:\n",
    "                    logger.error(f\"Gagal GET setelah retry: {url} | error: {e}\")\n",
    "                    return None\n",
    "            except RequestException as e:\n",
    "                logger.error(f\"RequestException: {e} | {url}\")\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    # ---------- Helpers URL ----------\n",
    "    def _build_news_url(self, date_str: str, page: int) -> str:\n",
    "        dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        return f\"{self.NEWS_INDEX_BASE}/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}?page={page}\"\n",
    "\n",
    "    def _build_bisnis_url(self, date_str: str, page: int) -> str:\n",
    "        # Sesuai permintaan: kanal Bisnis juga bertanggal\n",
    "        dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        return f\"{self.BISNIS_INDEX_BASE}/{dt.year:04d}/{dt.month:02d}/{dt.day:02d}?page={page}\"\n",
    "\n",
    "    # ---------- Normalisasi & parsing list ----------\n",
    "    def _normalize_text(self, s: str) -> str:\n",
    "        s = s.lower()\n",
    "        s = re.sub(r\"[^\\w\\s]\", \" \", s, flags=re.UNICODE)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return s\n",
    "\n",
    "    def _parse_list_page(self, html: str) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Ambil semua tautan artikel dari halaman indeks.\n",
    "        Strategi robust: cari semua <a> dengan href berisi '/read/' lalu deduplikasi.\n",
    "        Return: list dict { 'a': tag, 'url': full_url, 'title': title }\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        anchors = soup.select('a[href*=\"/read/\"]')\n",
    "\n",
    "        items, seen = [], set()\n",
    "        for a in anchors:\n",
    "            href = (a.get(\"href\") or \"\").strip()\n",
    "            title = (a.get_text(strip=True) or \"\").strip()\n",
    "            if not href or not title:\n",
    "                continue\n",
    "            full_url = urljoin(self.BASE, href)\n",
    "            if \"liputan6.com\" not in full_url or \"/read/\" not in full_url:\n",
    "                continue\n",
    "            key = (full_url, title.lower())\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            items.append({\"a\": a, \"url\": full_url, \"title\": title})\n",
    "        return items\n",
    "\n",
    "    # ---------- Ekstraksi item + analisis relevansi ----------\n",
    "    def _extract_article_data(self, item: dict, fallback_date: str, topic_keywords: list[str]) -> dict | None:\n",
    "        try:\n",
    "            title = item.get(\"title\", \"\").strip()\n",
    "            url = item.get(\"url\", \"\").strip()\n",
    "            if not title or not url:\n",
    "                return None\n",
    "\n",
    "            # Cari tanggal di sekitar anchor (listing). Jika tak ada, fallback ke tanggal indeks.\n",
    "            tanggal = \"\"\n",
    "            a = item.get(\"a\")\n",
    "            container = a.find_parent([\"li\", \"article\", \"div\"]) if a else None\n",
    "            time_tag = container.find(\"time\") if container else None\n",
    "            if not time_tag and a:\n",
    "                time_tag = a.find_next(\"time\")\n",
    "            if time_tag:\n",
    "                tanggal = (time_tag.get(\"datetime\") or time_tag.get_text(strip=True) or \"\").strip()\n",
    "            if not tanggal:\n",
    "                tanggal = fallback_date\n",
    "\n",
    "            penulis = \"Tidak Diketahui\"\n",
    "\n",
    "            # Relevansi judul\n",
    "            norm_title = self._normalize_text(title)\n",
    "            norm_keys = [self._normalize_text(k) for k in topic_keywords if k.strip()]\n",
    "            found = [kw for kw in norm_keys if kw and kw in norm_title]\n",
    "            relevan = bool(found)\n",
    "            keywords_found = \", \".join(found)\n",
    "\n",
    "            return {\n",
    "                \"judul_berita\": title,\n",
    "                \"tanggal_berita\": tanggal,\n",
    "                \"penulis_berita\": penulis,\n",
    "                \"url_berita\": url,\n",
    "                \"relevan\": relevan,\n",
    "                \"keywords_found\": keywords_found\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gagal parsing artikel: {e}\")\n",
    "            return None\n",
    "\n",
    "    # ---------- Scrape per tanggal (News & Bisnis) ----------\n",
    "    def _scrape_generic_by_date(self, build_url_fn, date_str: str, max_pages: int, topic_keywords: list[str], label: str) -> pd.DataFrame:\n",
    "        logger.info(f\"Memproses tanggal [{label}]: {date_str}\")\n",
    "        rows = []\n",
    "        for page in range(1, max_pages + 1):\n",
    "            url = build_url_fn(date_str, page)\n",
    "            logger.info(f\"GET {label}: {url}\")\n",
    "            resp = self._get(url)\n",
    "            if not resp:\n",
    "                logger.warning(f\"Gagal memuat halaman {label}, hentikan iterasi tanggal {date_str}\")\n",
    "                break\n",
    "\n",
    "            items = self._parse_list_page(resp.text)\n",
    "            logger.info(f\"{label} halaman {page}: ditemukan {len(items)} artikel\")\n",
    "            if not items:\n",
    "                logger.info(f\"Halaman kosong/pola tidak cocok ({label}), stop {date_str}\")\n",
    "                break\n",
    "\n",
    "            for it in items:\n",
    "                data = self._extract_article_data(it, fallback_date=date_str, topic_keywords=topic_keywords)\n",
    "                if data:\n",
    "                    rows.append(data)\n",
    "\n",
    "            time.sleep(self.sleep_between_pages)\n",
    "\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows).drop_duplicates(subset=[\"url_berita\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=[\"judul_berita\",\"tanggal_berita\",\"penulis_berita\",\"url_berita\",\"relevan\",\"keywords_found\"])\n",
    "        return df\n",
    "\n",
    "    def scrape_news_date(self, date_str: str, max_pages: int, topic_keywords: list[str]) -> pd.DataFrame:\n",
    "        return self._scrape_generic_by_date(self._build_news_url, date_str, max_pages, topic_keywords, label=\"News\")\n",
    "\n",
    "    def scrape_bisnis_date(self, date_str: str, max_pages: int, topic_keywords: list[str]) -> pd.DataFrame:\n",
    "        return self._scrape_generic_by_date(self._build_bisnis_url, date_str, max_pages, topic_keywords, label=\"Bisnis\")\n",
    "\n",
    "    # ---------- Orkestrasi ----------\n",
    "    def scrape_many(self, dates: list[str], max_pages: int, topic_keywords: list[str], include_bisnis: bool=True) -> pd.DataFrame:\n",
    "        frames = []\n",
    "\n",
    "        for d in dates:\n",
    "            try:\n",
    "                frames.append(self.scrape_news_date(d, max_pages, topic_keywords))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Gagal scraping News {d}: {e}\")\n",
    "\n",
    "        if include_bisnis:\n",
    "            for d in dates:\n",
    "                try:\n",
    "                    frames.append(self.scrape_bisnis_date(d, max_pages, topic_keywords))\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Gagal scraping Bisnis {d}: {e}\")\n",
    "\n",
    "        if not frames:\n",
    "            return pd.DataFrame(columns=[\"judul_berita\",\"tanggal_berita\",\"penulis_berita\",\"url_berita\",\"relevan\",\"keywords_found\"])\n",
    "\n",
    "        df_all = pd.concat(frames, ignore_index=True)\n",
    "        df_all = df_all.drop_duplicates(subset=[\"url_berita\"]).reset_index(drop=True)\n",
    "        df_all = df_all[[\"judul_berita\",\"tanggal_berita\",\"penulis_berita\",\"url_berita\",\"relevan\",\"keywords_found\"]]\n",
    "        return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 67121,
     "status": "ok",
     "timestamp": 1758161769338,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "R26ekPTiAiFk",
    "outputId": "9aede5f4-3717-434c-9deb-a0e38563c0c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:55:19 | INFO | Memproses tanggal [News]: 2025-09-24\n",
      "07:55:19 | INFO | GET News: https://www.liputan6.com/news/indeks/2025/09/24?page=1\n",
      "07:55:19 | INFO | News halaman 1: ditemukan 24 artikel\n",
      "07:55:20 | INFO | GET News: https://www.liputan6.com/news/indeks/2025/09/24?page=2\n",
      "07:55:20 | INFO | News halaman 2: ditemukan 24 artikel\n",
      "07:55:21 | INFO | GET News: https://www.liputan6.com/news/indeks/2025/09/24?page=3\n",
      "07:55:22 | INFO | News halaman 3: ditemukan 24 artikel\n",
      "07:55:23 | INFO | Memproses tanggal [Bisnis]: 2025-09-24\n",
      "07:55:23 | INFO | GET Bisnis: https://www.liputan6.com/bisnis/indeks/2025/09/24?page=1\n",
      "07:55:23 | INFO | Bisnis halaman 1: ditemukan 24 artikel\n",
      "07:55:24 | INFO | GET Bisnis: https://www.liputan6.com/bisnis/indeks/2025/09/24?page=2\n",
      "07:55:24 | INFO | Bisnis halaman 2: ditemukan 24 artikel\n",
      "07:55:25 | INFO | GET Bisnis: https://www.liputan6.com/bisnis/indeks/2025/09/24?page=3\n",
      "07:55:25 | INFO | Bisnis halaman 3: ditemukan 24 artikel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_berita</th>\n",
       "      <th>tanggal_berita</th>\n",
       "      <th>penulis_berita</th>\n",
       "      <th>url_berita</th>\n",
       "      <th>relevan</th>\n",
       "      <th>keywords_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wilayah Terdampak Gempa Banyuwangi 25 Septembe...</td>\n",
       "      <td>2025-09-25T21:00:22+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/cek-fakta/read/616889...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simak Jadwal Lengkap Hari Libur Nasional dan C...</td>\n",
       "      <td>2025-09-25T19:00:00+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/cek-fakta/read/616840...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pertamina Patra Niaga Ajak Konsumen Pastikan K...</td>\n",
       "      <td>2025-09-25T17:36:59+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/cek-fakta/read/616876...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cek Fakta: Hoaks Uang Pecahan Baru Rp 300 Ribu...</td>\n",
       "      <td>2025-09-25T15:00:00+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/cek-fakta/read/616830...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KPK Tangkap Seorang Pengusaha Terkait Kasus TP...</td>\n",
       "      <td>2025-09-24T23:25:41+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/news/read/6168036/kpk...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Seleksi Ketat CPNS Bisa Lahirkan PNS Anti Koru...</td>\n",
       "      <td>2025-09-24T11:00:10+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/bisnis/read/6167113/s...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>OECD Revisi Pertumbuhan Ekonomi Indonesia Naik...</td>\n",
       "      <td>2025-09-24T10:50:31+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/bisnis/read/6167310/o...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Saat Prabowo Pamer Produksi Beras Indonesia Ce...</td>\n",
       "      <td>2025-09-24T10:30:10+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/bisnis/read/6167170/s...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Kapan Gaji PNS Naik? Ini Bocorannya</td>\n",
       "      <td>2025-09-24T10:15:02+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/bisnis/read/6167117/k...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Heboh Kendaraan Alami Gangguan Mesin Usai Isi ...</td>\n",
       "      <td>2025-09-24T10:00:48+07:00</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.liputan6.com/bisnis/read/6167235/h...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          judul_berita  \\\n",
       "0    Wilayah Terdampak Gempa Banyuwangi 25 Septembe...   \n",
       "1    Simak Jadwal Lengkap Hari Libur Nasional dan C...   \n",
       "2    Pertamina Patra Niaga Ajak Konsumen Pastikan K...   \n",
       "3    Cek Fakta: Hoaks Uang Pecahan Baru Rp 300 Ribu...   \n",
       "4    KPK Tangkap Seorang Pengusaha Terkait Kasus TP...   \n",
       "..                                                 ...   \n",
       "119  Seleksi Ketat CPNS Bisa Lahirkan PNS Anti Koru...   \n",
       "120  OECD Revisi Pertumbuhan Ekonomi Indonesia Naik...   \n",
       "121  Saat Prabowo Pamer Produksi Beras Indonesia Ce...   \n",
       "122                Kapan Gaji PNS Naik? Ini Bocorannya   \n",
       "123  Heboh Kendaraan Alami Gangguan Mesin Usai Isi ...   \n",
       "\n",
       "                tanggal_berita   penulis_berita  \\\n",
       "0    2025-09-25T21:00:22+07:00  Tidak Diketahui   \n",
       "1    2025-09-25T19:00:00+07:00  Tidak Diketahui   \n",
       "2    2025-09-25T17:36:59+07:00  Tidak Diketahui   \n",
       "3    2025-09-25T15:00:00+07:00  Tidak Diketahui   \n",
       "4    2025-09-24T23:25:41+07:00  Tidak Diketahui   \n",
       "..                         ...              ...   \n",
       "119  2025-09-24T11:00:10+07:00  Tidak Diketahui   \n",
       "120  2025-09-24T10:50:31+07:00  Tidak Diketahui   \n",
       "121  2025-09-24T10:30:10+07:00  Tidak Diketahui   \n",
       "122  2025-09-24T10:15:02+07:00  Tidak Diketahui   \n",
       "123  2025-09-24T10:00:48+07:00  Tidak Diketahui   \n",
       "\n",
       "                                            url_berita  relevan keywords_found  \n",
       "0    https://www.liputan6.com/cek-fakta/read/616889...    False                 \n",
       "1    https://www.liputan6.com/cek-fakta/read/616840...    False                 \n",
       "2    https://www.liputan6.com/cek-fakta/read/616876...    False                 \n",
       "3    https://www.liputan6.com/cek-fakta/read/616830...    False                 \n",
       "4    https://www.liputan6.com/news/read/6168036/kpk...    False                 \n",
       "..                                                 ...      ...            ...  \n",
       "119  https://www.liputan6.com/bisnis/read/6167113/s...    False                 \n",
       "120  https://www.liputan6.com/bisnis/read/6167310/o...    False                 \n",
       "121  https://www.liputan6.com/bisnis/read/6167170/s...    False                 \n",
       "122  https://www.liputan6.com/bisnis/read/6167117/k...    False                 \n",
       "123  https://www.liputan6.com/bisnis/read/6167235/h...    False                 \n",
       "\n",
       "[124 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== RINGKASAN ====\n",
      "Total artikel: 124\n",
      "Artikel relevan: 5\n",
      "Contoh 5 judul relevan:\n",
      "1. Soal Gaya 'Koboi' Menkeu Purbaya, Begini Komentar Luhut Pandjaitan\n",
      "2. Defisit APBN Agustus Capai Rp 321,6 Triliun, Ini Dampaknya ke Stabilitas Fiskal\n",
      "3. Transfer Rp 200 Triliun ke Bank Himbara Ala Menkeu Purbaya Jadi Terobosan Penting\n",
      "4. Hotman Paris Protes Bunga Deposito Turun, Ini Jawaban Menohok Menkeu Purbaya\n",
      "5. Jurus Rahasia Menkeu Purbaya Tekan Utang Indonesia\n"
     ]
    }
   ],
   "source": [
    "# Sel 4: Eksekusi scraping & ringkasan\n",
    "\n",
    "# %%\n",
    "scraper = Liputan6Scraper(timeout=10, max_retries=3, sleep_between_pages=1.0)\n",
    "\n",
    "df = scraper.scrape_many(\n",
    "    dates=dates,\n",
    "    max_pages=max_pages_per_date,\n",
    "    topic_keywords=topic_keywords,\n",
    "    include_bisnis=include_bisnis\n",
    ")\n",
    "\n",
    "# Tampilkan DataFrame dengan urutan kolom sesuai spesifikasi\n",
    "expected_cols = [\"judul_berita\",\"tanggal_berita\",\"penulis_berita\",\"url_berita\",\"relevan\",\"keywords_found\"]\n",
    "df = df.reindex(columns=expected_cols)\n",
    "display(df)\n",
    "\n",
    "# Ringkasan\n",
    "total_artikel = len(df)\n",
    "total_relevan = int(df[\"relevan\"].sum()) if total_artikel else 0\n",
    "contoh_relevan = df[df[\"relevan\"]].head(5)[\"judul_berita\"].tolist()\n",
    "\n",
    "print(\"\\n==== RINGKASAN ====\")\n",
    "print(f\"Total artikel: {total_artikel}\")\n",
    "print(f\"Artikel relevan: {total_relevan}\")\n",
    "if contoh_relevan:\n",
    "    print(\"Contoh 5 judul relevan:\")\n",
    "    for i, j in enumerate(contoh_relevan, 1):\n",
    "        print(f\"{i}. {j}\")\n",
    "else:\n",
    "    print(\"Tidak ada contoh judul relevan.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1758162075792,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "zmdeeU9-nmqL"
   },
   "outputs": [],
   "source": [
    "df_out = df[df['relevan']==True]\n",
    "df_out = df_out[['judul_berita', 'tanggal_berita', 'penulis_berita', 'url_berita', 'keywords_found']]\n",
    "df_out.to_excel(cwd + \"/daftar_berita/liputan6.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPyEf7eFQPT08KN5YdwmiMh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
