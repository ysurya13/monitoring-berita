{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1758166595810,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "xElySt2V0BlW",
    "outputId": "20dd11a2-dcff-4307-a67a-ccd57042677b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# mount the colab with google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# mount the colab with google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u4EYRdMg0eNK"
   },
   "outputs": [],
   "source": [
    "# set folder tempat kerja (current working directory)\n",
    "import os\n",
    "cwd = '/Users/yusufpradana/Library/CloudStorage/OneDrive-Personal/Pekerjaan BMN/05. 2025/98_monitoring_berita'\n",
    "#cwd = '/content/drive/MyDrive/Monitoring Berita'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PcC13F_h0gzB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:54:30 | INFO | Environment ready. Libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Sel 1: Import & Logging Setup ---\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "from requests.exceptions import RequestException, HTTPError, Timeout\n",
    "\n",
    "# Logging format\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "\n",
    "logging.info(\"Environment ready. Libraries loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DbRGFHSin-DZ"
   },
   "outputs": [],
   "source": [
    "# --- Sel 2: Parameter (mudah diubah) ---\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Kata kunci topik untuk analisis relevansi judul\n",
    "topic_keywords = config[\"keywords\"]\n",
    "\n",
    "# Daftar tanggal (YYYY-MM-DD). Akan di-convert ke DD-MM-YYYY untuk pencocokan di halaman.\n",
    "dates = config[\"search_date\"]\n",
    "\n",
    "# Maksimum halaman per tanggal (akan berhenti lebih awal jika halaman kosong)\n",
    "max_pages_per_date = config[\"max_page_length\"]\n",
    "\n",
    "site_param = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6aCmxAB62QfK"
   },
   "outputs": [],
   "source": [
    "# --- Sel 3: KompasIndexScraper Class ---\n",
    "\n",
    "class KompasIndexScraper:\n",
    "    BASE = \"https://indeks.kompas.com\"\n",
    "\n",
    "    def __init__(self, timeout: int = 10):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "            )\n",
    "        })\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def _build_index_url(self, date_str: str, page: int, site: str) -> str:\n",
    "        \"\"\"\n",
    "        Pola indeks Kompas:\n",
    "        https://indeks.kompas.com/?site={site}&date=YYYY-MM-DD&page=PAGE\n",
    "        \"\"\"\n",
    "        return f\"{self.BASE}/?site={site}&date={date_str}&page={page}\"\n",
    "\n",
    "    def _request_with_retry(self, url: str, max_retries: int = 3, backoff_base: int = 1):\n",
    "        \"\"\"Retry untuk timeout / 5xx errors.\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = self.session.get(url, timeout=self.timeout)\n",
    "                resp.raise_for_status()\n",
    "                return resp\n",
    "            except Timeout as e:\n",
    "                logging.warning(f\"Timeout on {url} (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            except HTTPError as e:\n",
    "                code = getattr(e.response, \"status_code\", 0)\n",
    "                if 500 <= code < 600:\n",
    "                    logging.warning(f\"HTTP {code} on {url} (attempt {attempt+1}/{max_retries})\")\n",
    "                else:\n",
    "                    logging.error(f\"HTTP error {code} on {url}, not retrying.\")\n",
    "                    return None\n",
    "            except RequestException as e:\n",
    "                logging.error(f\"RequestException on {url}: {e}\")\n",
    "                return None\n",
    "\n",
    "            time.sleep(backoff_base * (2 ** attempt))\n",
    "        logging.error(f\"Failed after {max_retries} attempts: {url}\")\n",
    "        return None\n",
    "\n",
    "    def _parse_list_page(self, html: str | bytes):\n",
    "        \"\"\"\n",
    "        Mengambil elemen-artikel dari halaman indeks Kompas.\n",
    "        Struktur Kompas indeks: biasanya ada <h3 class=\"article__title\"> <a> … </a> … </h3>,\n",
    "        atau elemen dengan class article__list, article__title dll.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # Coba selector yang umum dipakai di Kompas indeks\n",
    "        items = soup.select(\"h3.article__title > a\")\n",
    "        if not items:\n",
    "            items = soup.select(\"h3.article__title.article__title--medium > a\")\n",
    "        if not items:\n",
    "            items = soup.select(\"div.article__list a.article__link\")\n",
    "        if not items:\n",
    "            # fallback generik: semua <a> yang punya /read/ dan di dalam listing\n",
    "            items = soup.select(\"a[href*='/read/']\")\n",
    "        return items\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_text(s: str) -> str:\n",
    "        s = s.lower()\n",
    "        s = re.sub(r\"[^0-9a-zA-Z\\s]\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return s\n",
    "\n",
    "    def _extract_article_data(self, a_tag, fallback_date: str, topic_keywords: list[str]) -> dict | None:\n",
    "        \"\"\"\n",
    "        Dari <a> tag atau elemen link, ekstrak title, tanggal, penulis jika ada, url.\n",
    "        Tanggal & penulis mungkin tidak ada di indeks -> fallback.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            judul = a_tag.get_text(strip=True)\n",
    "            href = a_tag.get(\"href\", \"\").strip()\n",
    "            if not judul or not href:\n",
    "                return None\n",
    "            url_abs = urljoin(self.BASE, href)\n",
    "\n",
    "            tanggal_berita = fallback_date\n",
    "            penulis = \"Tidak Diketahui\"\n",
    "\n",
    "            # Ada elemen tanggal di sebelah link / dalam kontainer\n",
    "            # Contoh: span.time, div.date, time[datetime]\n",
    "            parent = a_tag.parent\n",
    "            date_el = None\n",
    "            # naik ke atas beberapa level\n",
    "            for up in [a_tag, parent, parent.parent]:\n",
    "                if up is None:\n",
    "                    continue\n",
    "                date_el = up.select_one(\"time[datetime]\") or up.select_one(\"span.date\") or up.select_one(\"div.date\") or up.select_one(\"span.article__date\")\n",
    "                if date_el:\n",
    "                    break\n",
    "            if date_el:\n",
    "                if date_el.name == \"time\" and date_el.has_attr(\"datetime\"):\n",
    "                    tanggal_berita = date_el[\"datetime\"].strip()\n",
    "                else:\n",
    "                    tanggal_berita = date_el.get_text(strip=True)\n",
    "\n",
    "            # Penulis: elemen author/byline jika ada\n",
    "            author_el = None\n",
    "            for up in [a_tag, parent, parent.parent]:\n",
    "                if up is None:\n",
    "                    continue\n",
    "                author_el = up.select_one(\".author\") or up.select_one(\".article__author\") or up.select_one(\".read__author\") or up.select_one(\"span.author\")\n",
    "                if author_el:\n",
    "                    break\n",
    "            if author_el:\n",
    "                penulis_txt = author_el.get_text(\" \", strip=True)\n",
    "                penulis_txt = re.sub(r\"^(penulis\\s*:|oleh\\s*:?)\\s*\", \"\", penulis_txt, flags=re.I)\n",
    "                if penulis_txt:\n",
    "                    penulis = penulis_txt\n",
    "\n",
    "            # Relevansi berdasarkan keyword\n",
    "            norm_title = self._normalize_text(judul)\n",
    "            found = [kw for kw in topic_keywords if re.search(rf\"\\b{re.escape(kw.lower())}\\b\", norm_title)]\n",
    "            relevan = bool(found)\n",
    "            keywords_found = \", \".join(found)\n",
    "\n",
    "            return {\n",
    "                \"judul_berita\": judul,\n",
    "                \"tanggal_berita\": tanggal_berita,\n",
    "                \"penulis_berita\": penulis,\n",
    "                \"url_berita\": url_abs,\n",
    "                \"relevan\": relevan,\n",
    "                \"keywords_found\": keywords_found\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Gagal parsing satu artikel: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_date(self, date_str: str, max_pages: int, topic_keywords: list[str], site: str) -> pd.DataFrame:\n",
    "        all_rows = []\n",
    "        logging.info(f\"Memproses tanggal: {date_str}, site: {site}\")\n",
    "\n",
    "        for page in range(1, max_pages + 1):\n",
    "            url = self._build_index_url(date_str, page, site)\n",
    "            logging.info(f\"Fetch: {url}\")\n",
    "\n",
    "            resp = self._request_with_retry(url)\n",
    "            if resp is None:\n",
    "                logging.error(f\"Skip halaman (gagal ambil): {url}\")\n",
    "                break\n",
    "\n",
    "            items = self._parse_list_page(resp.text)\n",
    "            logging.info(f\"Kandidat link artikel di page {page}: {len(items)}\")\n",
    "\n",
    "            if not items:\n",
    "                logging.info(f\"Tidak ada artikel di page {page}. Stop iterasi untuk tanggal {date_str}.\")\n",
    "                break\n",
    "\n",
    "            count_ok = 0\n",
    "            for a_tag in items:\n",
    "                data = self._extract_article_data(a_tag, fallback_date=date_str, topic_keywords=topic_keywords)\n",
    "                if data:\n",
    "                    all_rows.append(data)\n",
    "                    count_ok += 1\n",
    "\n",
    "            logging.info(f\"Artikel berhasil diparse dari page {page}: {count_ok}\")\n",
    "\n",
    "            # Sleep antar halaman\n",
    "            time.sleep(1)\n",
    "\n",
    "        if not all_rows:\n",
    "            logging.warning(f\"Tidak ada data untuk tanggal {date_str}, site={site}\")\n",
    "\n",
    "        df = pd.DataFrame(all_rows, columns=[\n",
    "            \"judul_berita\",\n",
    "            \"tanggal_berita\",\n",
    "            \"penulis_berita\",\n",
    "            \"url_berita\",\n",
    "            \"relevan\",\n",
    "            \"keywords_found\"\n",
    "        ])\n",
    "        return df\n",
    "\n",
    "    def scrape_many(self, dates: list[str], max_pages: int, topic_keywords: list[str], site: str) -> pd.DataFrame:\n",
    "        frames = []\n",
    "        for ds in dates:\n",
    "            try:\n",
    "                datetime.strptime(ds, \"%Y-%m-%d\")\n",
    "            except ValueError:\n",
    "                logging.error(f\"Format tanggal salah (harus YYYY-MM-DD): {ds}\")\n",
    "                continue\n",
    "            df = self.scrape_date(ds, max_pages, topic_keywords, site)\n",
    "            if not df.empty:\n",
    "                frames.append(df)\n",
    "\n",
    "        if frames:\n",
    "            big = pd.concat(frames, ignore_index=True)\n",
    "            big = big.drop_duplicates(subset=[\"url_berita\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            big = pd.DataFrame(columns=[\n",
    "                \"judul_berita\",\n",
    "                \"tanggal_berita\",\n",
    "                \"penulis_berita\",\n",
    "                \"url_berita\",\n",
    "                \"relevan\",\n",
    "                \"keywords_found\"\n",
    "            ])\n",
    "        return big\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "executionInfo": {
     "elapsed": 198802,
     "status": "ok",
     "timestamp": 1758166794706,
     "user": {
      "displayName": "Monitoring Berita",
      "userId": "16755502473357078001"
     },
     "user_tz": -420
    },
    "id": "PCDLGBsS2SbX",
    "outputId": "77c511ac-2ba4-48dc-8cc3-10c892a01f8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:54:30 | INFO | Memproses tanggal: 2025-09-24, site: all\n",
      "07:54:30 | INFO | Fetch: https://indeks.kompas.com/?site=all&date=2025-09-24&page=1\n",
      "07:54:30 | INFO | Kandidat link artikel di page 1: 38\n",
      "07:54:30 | INFO | Artikel berhasil diparse dari page 1: 37\n",
      "07:54:31 | INFO | Fetch: https://indeks.kompas.com/?site=all&date=2025-09-24&page=2\n",
      "07:54:32 | INFO | Kandidat link artikel di page 2: 40\n",
      "07:54:32 | INFO | Artikel berhasil diparse dari page 2: 39\n",
      "07:54:33 | INFO | Fetch: https://indeks.kompas.com/?site=all&date=2025-09-24&page=3\n",
      "07:54:33 | INFO | Kandidat link artikel di page 3: 41\n",
      "07:54:33 | INFO | Artikel berhasil diparse dari page 3: 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_berita</th>\n",
       "      <th>tanggal_berita</th>\n",
       "      <th>penulis_berita</th>\n",
       "      <th>url_berita</th>\n",
       "      <th>relevan</th>\n",
       "      <th>keywords_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kisah di Balik Macet Parah di Jakarta Rabu Mal...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.kompas.com/banten/read/2025/09/24/...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nenek di Padang Pariaman Kritis Dianiaya Saat ...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://regional.kompas.com/read/2025/09/24/23...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kepala SPPG Bangka 2 Dorong Relawan Baca Berit...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://megapolitan.kompas.com/read/2025/09/24...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiap Tahun Dibongkar, Warga Harap Revitalisasi...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://megapolitan.kompas.com/read/2025/09/24...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beredar Kabar Keracunan MBG di SDN 07 Pulogeba...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://megapolitan.kompas.com/read/2025/09/24...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Bus Mogok di Flyover Slipi Perparah Macet di G...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://megapolitan.kompas.com/read/2025/09/24...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Tujuh Siswa yang Diduga Keracunan MBG di Jakut...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://megapolitan.kompas.com/read/2025/09/24...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>12 Tahun Bersembunyi, Akhirnya DPO Korupsi Hib...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://surabaya.kompas.com/read/2025/09/24/20...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Marsha Timothy Stres Syuting Film Tukar Takdir...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://www.kompas.com/hype/read/2025/09/24/20...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>PT Toba Pulp Lestari Bantah Aniaya Mahasiswi I...</td>\n",
       "      <td>2025-09-24</td>\n",
       "      <td>Tidak Diketahui</td>\n",
       "      <td>https://regional.kompas.com/read/2025/09/24/20...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          judul_berita tanggal_berita  \\\n",
       "0    Kisah di Balik Macet Parah di Jakarta Rabu Mal...     2025-09-24   \n",
       "1    Nenek di Padang Pariaman Kritis Dianiaya Saat ...     2025-09-24   \n",
       "2    Kepala SPPG Bangka 2 Dorong Relawan Baca Berit...     2025-09-24   \n",
       "3    Tiap Tahun Dibongkar, Warga Harap Revitalisasi...     2025-09-24   \n",
       "4    Beredar Kabar Keracunan MBG di SDN 07 Pulogeba...     2025-09-24   \n",
       "..                                                 ...            ...   \n",
       "111  Bus Mogok di Flyover Slipi Perparah Macet di G...     2025-09-24   \n",
       "112  Tujuh Siswa yang Diduga Keracunan MBG di Jakut...     2025-09-24   \n",
       "113  12 Tahun Bersembunyi, Akhirnya DPO Korupsi Hib...     2025-09-24   \n",
       "114  Marsha Timothy Stres Syuting Film Tukar Takdir...     2025-09-24   \n",
       "115  PT Toba Pulp Lestari Bantah Aniaya Mahasiswi I...     2025-09-24   \n",
       "\n",
       "      penulis_berita                                         url_berita  \\\n",
       "0    Tidak Diketahui  https://www.kompas.com/banten/read/2025/09/24/...   \n",
       "1    Tidak Diketahui  https://regional.kompas.com/read/2025/09/24/23...   \n",
       "2    Tidak Diketahui  https://megapolitan.kompas.com/read/2025/09/24...   \n",
       "3    Tidak Diketahui  https://megapolitan.kompas.com/read/2025/09/24...   \n",
       "4    Tidak Diketahui  https://megapolitan.kompas.com/read/2025/09/24...   \n",
       "..               ...                                                ...   \n",
       "111  Tidak Diketahui  https://megapolitan.kompas.com/read/2025/09/24...   \n",
       "112  Tidak Diketahui  https://megapolitan.kompas.com/read/2025/09/24...   \n",
       "113  Tidak Diketahui  https://surabaya.kompas.com/read/2025/09/24/20...   \n",
       "114  Tidak Diketahui  https://www.kompas.com/hype/read/2025/09/24/20...   \n",
       "115  Tidak Diketahui  https://regional.kompas.com/read/2025/09/24/20...   \n",
       "\n",
       "     relevan keywords_found  \n",
       "0      False                 \n",
       "1      False                 \n",
       "2      False                 \n",
       "3      False                 \n",
       "4      False                 \n",
       "..       ...            ...  \n",
       "111    False                 \n",
       "112    False                 \n",
       "113    False                 \n",
       "114    False                 \n",
       "115    False                 \n",
       "\n",
       "[116 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ringkasan ---\n",
      "Total artikel: 116\n",
      "Artikel relevan: 0\n",
      "Tidak ada judul relevan untuk ditampilkan.\n"
     ]
    }
   ],
   "source": [
    "# --- Sel 4: Run & Summary ---\n",
    "\n",
    "scraper = KompasIndexScraper()\n",
    "df = scraper.scrape_many(dates=dates, max_pages=max_pages_per_date, topic_keywords=topic_keywords, site=site_param)\n",
    "\n",
    "# Reindex kolom sesuai spesifikasi\n",
    "expected_cols = [\"judul_berita\",\"tanggal_berita\",\"penulis_berita\",\"url_berita\",\"relevan\",\"keywords_found\"]\n",
    "df = df.reindex(columns=expected_cols)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Ringkasan\n",
    "total = len(df)\n",
    "relevant = int(df[\"relevan\"].sum()) if total else 0\n",
    "samples = df.loc[df[\"relevan\"], \"judul_berita\"].head(5).tolist()\n",
    "\n",
    "print(\"\\n--- Ringkasan ---\")\n",
    "print(f\"Total artikel: {total}\")\n",
    "print(f\"Artikel relevan: {relevant}\")\n",
    "if samples:\n",
    "    print(\"Contoh 5 judul relevan:\")\n",
    "    for i, s in enumerate(samples, 1):\n",
    "        print(f\"{i}. {s}\")\n",
    "else:\n",
    "    print(\"Tidak ada judul relevan untuk ditampilkan.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tJYLSEps5UPw"
   },
   "outputs": [],
   "source": [
    "# simpan data artikel relevan ke excel\n",
    "df_output = df[df['relevan']==True]\n",
    "df_output = df_output[['judul_berita', 'tanggal_berita', 'penulis_berita', 'url_berita', 'keywords_found']]\n",
    "df_output.to_excel(cwd + '/daftar_berita/hasil_kompas.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNdB4aeAxYa9rLNE5ZYfZ1b",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
